{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamer017/Anomaly_baised_Intrusion_detection_system_CNN1D/blob/main/Anomaly_baised_Intrusion_detection_system_CNN1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKsDENfdQYIf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,plot_confusion_matrix,multilabel_confusion_matrix,classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential,Input\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "seed=13\n",
        "from imblearn.over_sampling import ADASYN ,SMOTE\n",
        "from imblearn.under_sampling import RepeatedEditedNearestNeighbours as RENN\n",
        "from imblearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh7hxTHeQefa",
        "outputId": "53a59318-9df3-466b-8941-895154098b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiE3Di7hQYIt"
      },
      "outputs": [],
      "source": [
        "KDDTrainPlus_BiClassification = pd.read_csv(r\"/content/drive/MyDrive/test/datasets/KDDTrain+.csv\")\n",
        "KDDTest21_BiClassification = pd.read_csv(r\"/content/drive/MyDrive/test/datasets/KDDTest+.csv\")\n",
        "KDDTestPlus_BiClassification = pd.read_csv(r\"/content/drive/MyDrive/test/datasets/KDDTest-21.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUc6TTxfSQXo"
      },
      "outputs": [],
      "source": [
        "def outputMapping(arr):\n",
        "    multiclass_attack={ 'normal': 'normal', \n",
        "        'probe': ['ipsweep.', 'nmap.', 'portsweep.','satan.', 'saint.', 'mscan.'], \n",
        "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.','teardrop.', 'apache2.', 'udpstorm.', 'processtable.','mailbomb.'], \n",
        "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.','xterm.', 'ps.', 'sqlattack.'], \n",
        "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.','phf.', 'spy.', 'warezclient.', 'warezmaster.','snmpgetattack.', \n",
        "                   'named.', 'xlock.', 'xsnoop.','sendmail.', 'httptunnel.', 'worm.', 'snmpguess.']}\n",
        "    attacks = ['normal' , 'probe' , 'dos' , 'u2r' ,'r2l']\n",
        "    for element in np.unique(arr):\n",
        "        for attack in attacks:\n",
        "            if element +\".\" in multiclass_attack[attack]:\n",
        "                arr[ arr == element] = attack\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJotDGknSvkR"
      },
      "outputs": [],
      "source": [
        "def getFeaturesNames():\n",
        "    features_name = pd.read_csv('/content/drive/MyDrive/test/datasets/Field Names.csv')\n",
        "    cols_name = features_name['duration'].tolist()\n",
        "    cols_name.insert(0 , \"duration\")\n",
        "    cols_name.append('classification')\n",
        "    cols_name.append('level')\n",
        "    return cols_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUCjKVczSV05"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Data Prepocessing including\n",
        "1- reading the csv file.\n",
        "2- seperate the output from the file.\n",
        "3- Applying OneHotEnocder to encode categorical features  into neumrical.\n",
        "4- Normalizing data to make the gredient descent run faster. \n",
        "'''\n",
        "def preprocessingBinaryClass(filePath , scaler = MinMaxScaler() , hotencoder = OneHotEncoder(), train = True):\n",
        "    dataframe = pd.read_csv(filePath,header=None)\n",
        "    dataframe.columns = getFeaturesNames()\n",
        "    dataframe.drop(['level'] , axis= 1 , inplace=True)\n",
        "    output=dataframe['classification'].values\n",
        "    output = output == 'normal'\n",
        "    dataframe.drop(['classification']  , axis= 1,inplace=True)\n",
        "    catFeatures =  dataframe.select_dtypes(include = \"object\")\n",
        "    dataframe.drop(catFeatures.columns , axis= 1 , inplace= True)\n",
        "    if train :\n",
        "        scaler.fit(dataframe)\n",
        "        hotencoder.fit(catFeatures)\n",
        "    encodedDataframe = pd.DataFrame(hotencoder.transform(catFeatures).toarray())\n",
        "    encodedDataframe.columns = hotencoder.get_feature_names_out()\n",
        "    tempCols = dataframe.columns\n",
        "    dataframe = pd.DataFrame(scaler.transform(dataframe) , columns = tempCols)\n",
        "    dataframe = pd.concat([dataframe , encodedDataframe] , axis= 1)\n",
        "    return dataframe , output , scaler ,hotencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2WyP46Uo3Ek"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Data Prepocessing including\n",
        "1- reading the csv file.\n",
        "2- seperate the output from the file.\n",
        "3- Applying OneHotEnocder to encode categorical features  into neumrical.\n",
        "4- Normalizing data to make the gredient descent run faster. \n",
        "'''\n",
        "def preprocessingFiveClasses(filePath , scaler = MinMaxScaler() , inEncoder = OneHotEncoder() , outEncoder = OneHotEncoder(), train = True):\n",
        "    dataframe = pd.read_csv(filePath,header=None)\n",
        "    dataframe.columns = getFeaturesNames()\n",
        "    output=pd.DataFrame(dataframe['classification'])\n",
        "    dataframe.drop(['classification']  , axis= 1,inplace=True)\n",
        "    dataframe.drop(['level']  , axis= 1,inplace=True)\n",
        "    catFeatures =  dataframe.select_dtypes(include = \"object\")\n",
        "    dataframe.drop(catFeatures.columns , axis= 1 , inplace= True)\n",
        "    output.classification=outputMapping(output.values)\n",
        "    if train :\n",
        "        scaler.fit(dataframe)\n",
        "        inEncoder.fit(catFeatures)\n",
        "        outEncoder.fit(output)\n",
        "    output = pd.DataFrame(outEncoder.transform(output).toarray())\n",
        "    output.columns=outEncoder.get_feature_names()    \n",
        "    encodedDataframe = pd.DataFrame(inEncoder.transform(catFeatures).toarray())\n",
        "    encodedDataframe.columns = inEncoder.get_feature_names_out()\n",
        "    tempCols = dataframe.columns\n",
        "    dataframe = pd.DataFrame(scaler.transform(dataframe) , columns = tempCols)\n",
        "    dataframe = pd.concat([dataframe , encodedDataframe] , axis= 1)\n",
        "    return dataframe , output , scaler ,inEncoder , outEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R63_gbgbQYJi"
      },
      "outputs": [],
      "source": [
        "def BI_CNN1D(input_train,output_train,testinput,testoutput,lr,std):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    input=Input(shape=(122))\n",
        "    reshape=layers.Reshape((1,122))(input)\n",
        "    layer1=layers.Conv1D(filters=32,activation=\"ReLU\",name=\"Conv1d_1\",kernel_size=3,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(reshape)\n",
        "    layer1=layers.MaxPooling1D(pool_size=2,strides=1,name=\"MaxPooling_1\",padding=\"same\")(layer1)\n",
        "    layer1=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_1\")(layer1)\n",
        "    flatten1=layers.Flatten()(layer1)\n",
        "\n",
        "    layer2=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_2\",kernel_size=4,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer1)\n",
        "    layer2=layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling_2\",padding=\"same\")(layer2)\n",
        "    layer2=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_2\")(layer2)\n",
        "    flatten2=layers.Flatten()(layer2)\n",
        "\n",
        "    layer3=layers.Conv1D(filters=124,activation=\"ReLU\",name=\"Conv1d_3\",kernel_size=8,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer2)\n",
        "    layer3=layers.MaxPool1D(pool_size=8,strides=1,name=\"MaxPooling_3\",padding=\"same\")(layer3)\n",
        "    layer3=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_3\")(layer3)\n",
        "    flatten3=layers.Flatten()(layer3)\n",
        "    \n",
        "    Dense1=Dense(256,activation=\"relu\",name=\"Dense_Layer_1\", kernel_initializer=initializers.RandomNormal(stddev=std), bias_initializer=initializers.Zeros())(flatten3)\n",
        "    dropout=layers.Dropout(rate=0.1,name=\"Dropoutlayer_4\")(Dense1)\n",
        "    Dense2=Dense(5,activation=\"softmax\",name=\"Dense_Layer_2\", kernel_initializer=initializers.RandomNormal(stddev=std), bias_initializer=initializers.Zeros())(dropout)\n",
        "    x=layers.Concatenate()([Dense2,flatten3,flatten2,flatten1])\n",
        "    output=Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=std), bias_initializer=initializers.Zeros())(x)\n",
        "    model=keras.Model(inputs=input,outputs=output)\n",
        "    class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(trainOutput),y=trainOutput)\n",
        "    dct={}\n",
        "    for index,weight in enumerate(class_weights):\n",
        "      dct[index]=weight\n",
        "    model._name=\"Multi-Stage_features_CNN1D\"\n",
        "    decaying_learning_rate=tf.keras.callbacks.LearningRateScheduler(lambda epoch: 5e-1 if epoch<108 else 1e-3 )\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=lr),metrics=['accuracy'])\n",
        "    history=model.fit(input_train,output_train,epochs=500,batch_size=128,validation_data=(testinput,testoutput),class_weight=dct,callbacks=[early_stop])\n",
        "    return model,history\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdP-LMkB6fmK"
      },
      "outputs": [],
      "source": [
        "def MULTI_CNN1D(input_train,output_train,testinput,testoutput,lr,stddev):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    input=Input(shape=(122))\n",
        "    reshape=layers.Reshape((1,122))(input)\n",
        "    layer1=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_1\",kernel_size=2,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(reshape)\n",
        "    layer1=layers.MaxPooling1D(pool_size=2,strides=1,name=\"MaxPooling_1\",padding=\"same\")(layer1)\n",
        "    layer1=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_1\")(layer1)\n",
        "    flatten1=layers.Flatten()(layer1)\n",
        "\n",
        "    layer2=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_2\",kernel_size=4,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer1)\n",
        "    layer2=layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling_2\",padding=\"same\")(layer2)\n",
        "    layer2=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_2\")(layer2)\n",
        "    flatten2=layers.Flatten()(layer2)\n",
        "\n",
        "    layer3=layers.Conv1D(filters=124,activation=\"ReLU\",name=\"Conv1d_3\",kernel_size=8,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer2)\n",
        "    layer3=layers.MaxPool1D(pool_size=8,strides=1,name=\"MaxPooling_3\",padding=\"same\")(layer3)\n",
        "    layer3=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_3\")(layer3)\n",
        "    flatten3=layers.Flatten()(layer3)\n",
        "    \n",
        "    Dense1=Dense(256,activation=\"relu\",name=\"Dense_Layer_1\", kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(flatten3)\n",
        "    dropout=layers.Dropout(rate=0.1,name=\"Dropoutlayer_4\")(Dense1)\n",
        "    Dense2=Dense(5,activation=\"softmax\",name=\"Dense_Layer_2\", kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(dropout)\n",
        "    x=layers.Concatenate()([Dense2,flatten3,flatten2,flatten1])\n",
        "    output=Dense(5,activation=\"linear\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=stddev), bias_initializer=initializers.Zeros())(x)\n",
        "    model=keras.Model(inputs=input,outputs=output)\n",
        "    model._name=\"Multi-Stage_features_CNN1D\"\n",
        "    out=np.zeros((trainOutput.shape[0],))\n",
        "    for index in range(1,6):\n",
        "      out+=index*trainOutput.values[:,index-1]\n",
        "    out-=1\n",
        "    class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(out),y=out)\n",
        "    dct={}\n",
        "    for index,weight in enumerate(class_weights):\n",
        "      dct[index]=weight\n",
        "    decaying_learning_rate=tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0000001 if epoch<74 else 0.00005)\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=150)\n",
        "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True,),optimizer=tf.optimizers.Adam(learning_rate=lr),metrics=['accuracy'])\n",
        "    history=model.fit(input_train,output_train,epochs=500,batch_size=1024,validation_data=(testinput,testoutput),class_weight=dct,callbacks=[early_stop])\n",
        "    return model,history\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0MlZa8ISlS6",
        "outputId": "29440fd2-d63d-4abc-bc16-47ca6bbf654f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# trainInput , trainOutput ,  scaler , encoder = preprocessingBinaryClass('/content/drive/MyDrive/test/datasets/KDDTrain+.csv')\n",
        "# testInput , testOutput , *_ = preprocessingBinaryClass('/content/drive/MyDrive/test/datasets/KDDTest+.csv' , scaler , encoder, False)\n",
        "# test21Input , test21Output , *_ = preprocessingBinaryClass('/content/drive/MyDrive/test/datasets/KDDTest-21.csv' ,  scaler , encoder,False)\n",
        "trainInput , trainOutput , scaler , inEncoder , outEncoder = preprocessingFiveClasses('/content/drive/MyDrive/test/datasets/KDDTrain+.csv')\n",
        "testInput , testOutput , *_ = preprocessingFiveClasses('/content/drive/MyDrive/test/datasets/KDDTest+.csv' , scaler , inEncoder , outEncoder , False)\n",
        "test21Input , test21Output , *_ = preprocessingFiveClasses('/content/drive/MyDrive/test/datasets/KDDTest-21.csv' , scaler , inEncoder , outEncoder , False)\n",
        "undersample=RENN()\n",
        "oversample=ADASYN()\n",
        "steps=[(\"o\",oversample), (\"u\",undersample)]\n",
        "# steps=[(\"o\",oversample)]\n",
        "pipeline=Pipeline (steps=steps)\n",
        "# trainInput,trainOutput=pipeline.fit_resample(trainInput.values,trainOutput.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo2SSXl-R5_D",
        "outputId": "5f71eeb5-069b-4152-8eb6-8e5db3a62ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "124/124 [==============================] - 10s 68ms/step - loss: 1.9631 - accuracy: 0.7011 - val_loss: 2.5971 - val_accuracy: 0.4554\n",
            "Epoch 2/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.6295 - accuracy: 0.8468 - val_loss: 2.5385 - val_accuracy: 0.5486\n",
            "Epoch 3/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.5801 - accuracy: 0.8575 - val_loss: 3.2839 - val_accuracy: 0.4427\n",
            "Epoch 4/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5227 - accuracy: 0.8627 - val_loss: 2.5935 - val_accuracy: 0.4696\n",
            "Epoch 5/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5138 - accuracy: 0.8646 - val_loss: 2.9087 - val_accuracy: 0.4740\n",
            "Epoch 6/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5132 - accuracy: 0.8635 - val_loss: 3.2334 - val_accuracy: 0.5640\n",
            "Epoch 7/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5232 - accuracy: 0.8749 - val_loss: 3.7092 - val_accuracy: 0.5651\n",
            "Epoch 8/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4968 - accuracy: 0.8733 - val_loss: 4.1294 - val_accuracy: 0.5645\n",
            "Epoch 9/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5283 - accuracy: 0.8490 - val_loss: 3.8470 - val_accuracy: 0.5216\n",
            "Epoch 10/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.5355 - accuracy: 0.8421 - val_loss: 3.9662 - val_accuracy: 0.3980\n",
            "Epoch 11/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.9191 - accuracy: 0.8237 - val_loss: 3.1437 - val_accuracy: 0.4331\n",
            "Epoch 12/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.6669 - accuracy: 0.6906 - val_loss: 3.0156 - val_accuracy: 0.4274\n",
            "Epoch 13/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.7557 - accuracy: 0.6246 - val_loss: 3.5223 - val_accuracy: 0.4266\n",
            "Epoch 14/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.7114 - accuracy: 0.6246 - val_loss: 3.6300 - val_accuracy: 0.4243\n",
            "Epoch 15/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.6648 - accuracy: 0.6473 - val_loss: 4.6672 - val_accuracy: 0.4446\n",
            "Epoch 16/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5562 - accuracy: 0.8515 - val_loss: 4.4325 - val_accuracy: 0.3479\n",
            "Epoch 17/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5147 - accuracy: 0.8563 - val_loss: 4.4237 - val_accuracy: 0.5473\n",
            "Epoch 18/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4988 - accuracy: 0.8594 - val_loss: 4.9689 - val_accuracy: 0.5396\n",
            "Epoch 19/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5026 - accuracy: 0.8596 - val_loss: 5.4663 - val_accuracy: 0.4201\n",
            "Epoch 20/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.5299 - accuracy: 0.8622 - val_loss: 5.4872 - val_accuracy: 0.4461\n",
            "Epoch 21/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4766 - accuracy: 0.8854 - val_loss: 5.6255 - val_accuracy: 0.4554\n",
            "Epoch 22/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4649 - accuracy: 0.8905 - val_loss: 5.1761 - val_accuracy: 0.4498\n",
            "Epoch 23/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4703 - accuracy: 0.8934 - val_loss: 4.8948 - val_accuracy: 0.5452\n",
            "Epoch 24/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4438 - accuracy: 0.8967 - val_loss: 5.4610 - val_accuracy: 0.5340\n",
            "Epoch 25/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4422 - accuracy: 0.8972 - val_loss: 5.7633 - val_accuracy: 0.4511\n",
            "Epoch 26/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4448 - accuracy: 0.8890 - val_loss: 6.4778 - val_accuracy: 0.4620\n",
            "Epoch 27/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4420 - accuracy: 0.8952 - val_loss: 5.0757 - val_accuracy: 0.4511\n",
            "Epoch 28/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4375 - accuracy: 0.9010 - val_loss: 5.6479 - val_accuracy: 0.4457\n",
            "Epoch 29/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4434 - accuracy: 0.9001 - val_loss: 5.9070 - val_accuracy: 0.5458\n",
            "Epoch 30/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4380 - accuracy: 0.8975 - val_loss: 6.4888 - val_accuracy: 0.4570\n",
            "Epoch 31/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4348 - accuracy: 0.9000 - val_loss: 6.9141 - val_accuracy: 0.4543\n",
            "Epoch 32/500\n",
            "124/124 [==============================] - 7s 56ms/step - loss: 0.4457 - accuracy: 0.8996 - val_loss: 5.6117 - val_accuracy: 0.4332\n",
            "Epoch 33/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.4856 - accuracy: 0.8692 - val_loss: 6.3149 - val_accuracy: 0.4344\n",
            "Epoch 34/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 1.3371 - accuracy: 0.8674 - val_loss: 5.5539 - val_accuracy: 0.5691\n",
            "Epoch 35/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5286 - accuracy: 0.8803 - val_loss: 6.6233 - val_accuracy: 0.5736\n",
            "Epoch 36/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5219 - accuracy: 0.8827 - val_loss: 7.1142 - val_accuracy: 0.5746\n",
            "Epoch 37/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5089 - accuracy: 0.8861 - val_loss: 7.9608 - val_accuracy: 0.4620\n",
            "Epoch 38/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5125 - accuracy: 0.8862 - val_loss: 8.6173 - val_accuracy: 0.4610\n",
            "Epoch 39/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5125 - accuracy: 0.8850 - val_loss: 7.5391 - val_accuracy: 0.4967\n",
            "Epoch 40/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.5352 - accuracy: 0.8827 - val_loss: 7.8430 - val_accuracy: 0.4633\n",
            "Epoch 41/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5274 - accuracy: 0.8866 - val_loss: 8.6939 - val_accuracy: 0.4678\n",
            "Epoch 42/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5330 - accuracy: 0.8805 - val_loss: 7.4250 - val_accuracy: 0.5359\n",
            "Epoch 43/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5249 - accuracy: 0.8835 - val_loss: 8.0893 - val_accuracy: 0.5635\n",
            "Epoch 44/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5568 - accuracy: 0.8811 - val_loss: 6.5445 - val_accuracy: 0.4174\n",
            "Epoch 45/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5904 - accuracy: 0.8253 - val_loss: 6.3698 - val_accuracy: 0.5732\n",
            "Epoch 46/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5433 - accuracy: 0.8496 - val_loss: 7.8817 - val_accuracy: 0.4511\n",
            "Epoch 47/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5517 - accuracy: 0.8548 - val_loss: 7.7555 - val_accuracy: 0.4380\n",
            "Epoch 48/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5431 - accuracy: 0.8561 - val_loss: 9.3105 - val_accuracy: 0.5619\n",
            "Epoch 49/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.6362 - accuracy: 0.8599 - val_loss: 8.6250 - val_accuracy: 0.3902\n",
            "Epoch 50/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5736 - accuracy: 0.8441 - val_loss: 11.1137 - val_accuracy: 0.4419\n",
            "Epoch 51/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5718 - accuracy: 0.8499 - val_loss: 10.9304 - val_accuracy: 0.5549\n",
            "Epoch 52/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5459 - accuracy: 0.8561 - val_loss: 11.2577 - val_accuracy: 0.4282\n",
            "Epoch 53/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.5491 - accuracy: 0.8565 - val_loss: 11.7314 - val_accuracy: 0.5078\n",
            "Epoch 54/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5664 - accuracy: 0.8547 - val_loss: 11.9458 - val_accuracy: 0.4236\n",
            "Epoch 55/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5671 - accuracy: 0.8598 - val_loss: 12.1306 - val_accuracy: 0.5543\n",
            "Epoch 56/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5497 - accuracy: 0.8611 - val_loss: 12.2723 - val_accuracy: 0.4269\n",
            "Epoch 57/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5455 - accuracy: 0.8629 - val_loss: 12.6203 - val_accuracy: 0.5524\n",
            "Epoch 58/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5497 - accuracy: 0.8555 - val_loss: 11.5717 - val_accuracy: 0.5584\n",
            "Epoch 59/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5510 - accuracy: 0.8579 - val_loss: 12.3262 - val_accuracy: 0.3651\n",
            "Epoch 60/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5656 - accuracy: 0.8558 - val_loss: 11.3007 - val_accuracy: 0.4273\n",
            "Epoch 61/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5419 - accuracy: 0.8622 - val_loss: 11.2117 - val_accuracy: 0.4224\n",
            "Epoch 62/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5409 - accuracy: 0.8647 - val_loss: 12.0310 - val_accuracy: 0.4227\n",
            "Epoch 63/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5386 - accuracy: 0.8753 - val_loss: 11.9585 - val_accuracy: 0.5571\n",
            "Epoch 64/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5303 - accuracy: 0.8786 - val_loss: 10.2295 - val_accuracy: 0.4379\n",
            "Epoch 65/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5140 - accuracy: 0.8828 - val_loss: 8.5730 - val_accuracy: 0.5646\n",
            "Epoch 66/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5272 - accuracy: 0.8834 - val_loss: 8.5958 - val_accuracy: 0.5561\n",
            "Epoch 67/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5583 - accuracy: 0.8645 - val_loss: 8.2795 - val_accuracy: 0.4231\n",
            "Epoch 68/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5660 - accuracy: 0.8431 - val_loss: 9.7633 - val_accuracy: 0.5534\n",
            "Epoch 69/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5338 - accuracy: 0.8635 - val_loss: 10.4261 - val_accuracy: 0.5531\n",
            "Epoch 70/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5489 - accuracy: 0.8637 - val_loss: 10.8964 - val_accuracy: 0.5119\n",
            "Epoch 71/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5467 - accuracy: 0.8654 - val_loss: 10.5827 - val_accuracy: 0.5549\n",
            "Epoch 72/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5380 - accuracy: 0.8684 - val_loss: 10.4192 - val_accuracy: 0.4247\n",
            "Epoch 73/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5625 - accuracy: 0.8682 - val_loss: 10.4572 - val_accuracy: 0.5587\n",
            "Epoch 74/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5293 - accuracy: 0.8723 - val_loss: 11.2575 - val_accuracy: 0.5689\n",
            "Epoch 75/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.5214 - accuracy: 0.8823 - val_loss: 11.2302 - val_accuracy: 0.4544\n",
            "Epoch 76/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 1.3202 - accuracy: 0.8296 - val_loss: 10.3525 - val_accuracy: 0.5549\n",
            "Epoch 77/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5829 - accuracy: 0.8290 - val_loss: 11.0587 - val_accuracy: 0.5635\n",
            "Epoch 78/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5662 - accuracy: 0.8446 - val_loss: 10.7798 - val_accuracy: 0.5673\n",
            "Epoch 79/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5613 - accuracy: 0.8481 - val_loss: 11.2850 - val_accuracy: 0.5630\n",
            "Epoch 80/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5517 - accuracy: 0.8562 - val_loss: 12.3938 - val_accuracy: 0.3830\n",
            "Epoch 81/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5644 - accuracy: 0.8473 - val_loss: 12.4135 - val_accuracy: 0.4262\n",
            "Epoch 82/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5477 - accuracy: 0.8589 - val_loss: 13.8418 - val_accuracy: 0.4235\n",
            "Epoch 83/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5433 - accuracy: 0.8542 - val_loss: 12.1163 - val_accuracy: 0.5469\n",
            "Epoch 84/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5436 - accuracy: 0.8502 - val_loss: 12.6740 - val_accuracy: 0.5800\n",
            "Epoch 85/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5409 - accuracy: 0.8608 - val_loss: 13.0056 - val_accuracy: 0.3784\n",
            "Epoch 86/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5488 - accuracy: 0.8553 - val_loss: 11.0871 - val_accuracy: 0.5498\n",
            "Epoch 87/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5406 - accuracy: 0.8640 - val_loss: 11.6277 - val_accuracy: 0.5905\n",
            "Epoch 88/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5231 - accuracy: 0.8754 - val_loss: 11.9440 - val_accuracy: 0.4683\n",
            "Epoch 89/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5340 - accuracy: 0.8777 - val_loss: 12.4778 - val_accuracy: 0.4354\n",
            "Epoch 90/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5381 - accuracy: 0.8747 - val_loss: 11.3325 - val_accuracy: 0.4792\n",
            "Epoch 91/500\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 0.5132 - accuracy: 0.8817 - val_loss: 15.1653 - val_accuracy: 0.5871\n",
            "Epoch 92/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4937 - accuracy: 0.9136 - val_loss: 8.6619 - val_accuracy: 0.4893\n",
            "Epoch 93/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4477 - accuracy: 0.9206 - val_loss: 7.6846 - val_accuracy: 0.5576\n",
            "Epoch 94/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4361 - accuracy: 0.9196 - val_loss: 8.1421 - val_accuracy: 0.5587\n",
            "Epoch 95/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4755 - accuracy: 0.8981 - val_loss: 8.4711 - val_accuracy: 0.5562\n",
            "Epoch 96/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4715 - accuracy: 0.9029 - val_loss: 8.4583 - val_accuracy: 0.5575\n",
            "Epoch 97/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.4732 - accuracy: 0.8990 - val_loss: 11.2065 - val_accuracy: 0.5606\n",
            "Epoch 98/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5162 - accuracy: 0.9188 - val_loss: 10.8677 - val_accuracy: 0.4645\n",
            "Epoch 99/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4739 - accuracy: 0.9073 - val_loss: 11.3922 - val_accuracy: 0.3537\n",
            "Epoch 100/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5238 - accuracy: 0.8948 - val_loss: 9.3074 - val_accuracy: 0.5544\n",
            "Epoch 101/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4960 - accuracy: 0.9013 - val_loss: 10.2928 - val_accuracy: 0.5443\n",
            "Epoch 102/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4798 - accuracy: 0.8942 - val_loss: 10.0304 - val_accuracy: 0.5683\n",
            "Epoch 103/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4855 - accuracy: 0.8972 - val_loss: 10.7795 - val_accuracy: 0.5678\n",
            "Epoch 104/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4677 - accuracy: 0.8996 - val_loss: 11.6726 - val_accuracy: 0.5705\n",
            "Epoch 105/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4757 - accuracy: 0.9010 - val_loss: 11.8714 - val_accuracy: 0.5620\n",
            "Epoch 106/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4682 - accuracy: 0.9072 - val_loss: 13.3294 - val_accuracy: 0.5642\n",
            "Epoch 107/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4656 - accuracy: 0.9097 - val_loss: 12.8753 - val_accuracy: 0.5649\n",
            "Epoch 108/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4576 - accuracy: 0.9154 - val_loss: 12.3531 - val_accuracy: 0.4560\n",
            "Epoch 109/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4554 - accuracy: 0.9179 - val_loss: 10.8007 - val_accuracy: 0.4885\n",
            "Epoch 110/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4449 - accuracy: 0.9165 - val_loss: 9.6928 - val_accuracy: 0.5095\n",
            "Epoch 111/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4451 - accuracy: 0.9192 - val_loss: 9.5016 - val_accuracy: 0.5511\n",
            "Epoch 112/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4461 - accuracy: 0.9188 - val_loss: 9.4363 - val_accuracy: 0.5208\n",
            "Epoch 113/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4427 - accuracy: 0.9192 - val_loss: 8.9897 - val_accuracy: 0.5976\n",
            "Epoch 114/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4416 - accuracy: 0.9202 - val_loss: 10.0525 - val_accuracy: 0.4801\n",
            "Epoch 115/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4337 - accuracy: 0.9199 - val_loss: 9.2598 - val_accuracy: 0.5526\n",
            "Epoch 116/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4748 - accuracy: 0.8984 - val_loss: 11.5130 - val_accuracy: 0.4624\n",
            "Epoch 117/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4593 - accuracy: 0.9051 - val_loss: 12.5862 - val_accuracy: 0.5667\n",
            "Epoch 118/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.4754 - accuracy: 0.9137 - val_loss: 13.5709 - val_accuracy: 0.6124\n",
            "Epoch 119/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4598 - accuracy: 0.9146 - val_loss: 11.7858 - val_accuracy: 0.4733\n",
            "Epoch 120/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4555 - accuracy: 0.9084 - val_loss: 13.4990 - val_accuracy: 0.6258\n",
            "Epoch 121/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4533 - accuracy: 0.9103 - val_loss: 13.1624 - val_accuracy: 0.6062\n",
            "Epoch 122/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.5336 - accuracy: 0.8777 - val_loss: 11.2245 - val_accuracy: 0.5640\n",
            "Epoch 123/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4964 - accuracy: 0.8803 - val_loss: 11.8528 - val_accuracy: 0.5970\n",
            "Epoch 124/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4819 - accuracy: 0.8905 - val_loss: 13.5583 - val_accuracy: 0.5000\n",
            "Epoch 125/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4710 - accuracy: 0.9071 - val_loss: 15.0566 - val_accuracy: 0.5062\n",
            "Epoch 126/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4499 - accuracy: 0.9172 - val_loss: 17.0492 - val_accuracy: 0.5035\n",
            "Epoch 127/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4463 - accuracy: 0.9165 - val_loss: 17.2025 - val_accuracy: 0.5684\n",
            "Epoch 128/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4372 - accuracy: 0.9190 - val_loss: 16.8022 - val_accuracy: 0.4669\n",
            "Epoch 129/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.6371 - accuracy: 0.9019 - val_loss: 20.0660 - val_accuracy: 0.5613\n",
            "Epoch 130/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4603 - accuracy: 0.9072 - val_loss: 20.0757 - val_accuracy: 0.4874\n",
            "Epoch 131/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4623 - accuracy: 0.9122 - val_loss: 20.6037 - val_accuracy: 0.5630\n",
            "Epoch 132/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4642 - accuracy: 0.9175 - val_loss: 17.2492 - val_accuracy: 0.4851\n",
            "Epoch 133/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4491 - accuracy: 0.9139 - val_loss: 15.1230 - val_accuracy: 0.5890\n",
            "Epoch 134/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4966 - accuracy: 0.9006 - val_loss: 16.0373 - val_accuracy: 0.6148\n",
            "Epoch 135/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4487 - accuracy: 0.9182 - val_loss: 15.4628 - val_accuracy: 0.4657\n",
            "Epoch 136/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4556 - accuracy: 0.9144 - val_loss: 15.1788 - val_accuracy: 0.6032\n",
            "Epoch 137/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4438 - accuracy: 0.9161 - val_loss: 14.2356 - val_accuracy: 0.4712\n",
            "Epoch 138/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4491 - accuracy: 0.9178 - val_loss: 14.1479 - val_accuracy: 0.5511\n",
            "Epoch 139/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.4524 - accuracy: 0.9187 - val_loss: 14.1672 - val_accuracy: 0.5456\n",
            "Epoch 140/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4392 - accuracy: 0.9185 - val_loss: 13.9999 - val_accuracy: 0.4527\n",
            "Epoch 141/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4610 - accuracy: 0.9147 - val_loss: 13.1328 - val_accuracy: 0.5905\n",
            "Epoch 142/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4582 - accuracy: 0.9179 - val_loss: 13.2087 - val_accuracy: 0.4397\n",
            "Epoch 143/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4529 - accuracy: 0.9179 - val_loss: 14.8729 - val_accuracy: 0.5721\n",
            "Epoch 144/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4337 - accuracy: 0.9211 - val_loss: 14.6221 - val_accuracy: 0.4999\n",
            "Epoch 145/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4601 - accuracy: 0.9136 - val_loss: 15.5228 - val_accuracy: 0.5835\n",
            "Epoch 146/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4662 - accuracy: 0.9080 - val_loss: 16.3143 - val_accuracy: 0.5922\n",
            "Epoch 147/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4711 - accuracy: 0.9122 - val_loss: 16.3306 - val_accuracy: 0.5443\n",
            "Epoch 148/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4540 - accuracy: 0.9195 - val_loss: 12.5889 - val_accuracy: 0.5864\n",
            "Epoch 149/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4327 - accuracy: 0.9202 - val_loss: 12.7343 - val_accuracy: 0.5476\n",
            "Epoch 150/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4319 - accuracy: 0.9243 - val_loss: 12.7611 - val_accuracy: 0.4426\n",
            "Epoch 151/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4368 - accuracy: 0.9217 - val_loss: 13.6325 - val_accuracy: 0.4833\n",
            "Epoch 152/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4365 - accuracy: 0.9195 - val_loss: 11.1979 - val_accuracy: 0.5374\n",
            "Epoch 153/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4280 - accuracy: 0.9208 - val_loss: 11.1845 - val_accuracy: 0.5575\n",
            "Epoch 154/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4352 - accuracy: 0.9194 - val_loss: 10.9272 - val_accuracy: 0.4813\n",
            "Epoch 155/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4333 - accuracy: 0.9218 - val_loss: 11.7240 - val_accuracy: 0.4637\n",
            "Epoch 156/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4717 - accuracy: 0.9117 - val_loss: 12.0903 - val_accuracy: 0.4819\n",
            "Epoch 157/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4469 - accuracy: 0.9196 - val_loss: 10.9220 - val_accuracy: 0.4973\n",
            "Epoch 158/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4452 - accuracy: 0.9200 - val_loss: 13.9592 - val_accuracy: 0.4922\n",
            "Epoch 159/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.5134 - accuracy: 0.9117 - val_loss: 8.2430 - val_accuracy: 0.4804\n",
            "Epoch 160/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4819 - accuracy: 0.9048 - val_loss: 12.2577 - val_accuracy: 0.5711\n",
            "Epoch 161/500\n",
            "124/124 [==============================] - 7s 58ms/step - loss: 0.4609 - accuracy: 0.9154 - val_loss: 10.7791 - val_accuracy: 0.4843\n",
            "Epoch 162/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4340 - accuracy: 0.9205 - val_loss: 11.5609 - val_accuracy: 0.5395\n",
            "Epoch 163/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4382 - accuracy: 0.9219 - val_loss: 10.9118 - val_accuracy: 0.5064\n",
            "Epoch 164/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4582 - accuracy: 0.9076 - val_loss: 12.5030 - val_accuracy: 0.5748\n",
            "Epoch 165/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4648 - accuracy: 0.9114 - val_loss: 12.8975 - val_accuracy: 0.4594\n",
            "Epoch 166/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4474 - accuracy: 0.9164 - val_loss: 12.0339 - val_accuracy: 0.4594\n",
            "Epoch 167/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4598 - accuracy: 0.9164 - val_loss: 10.6664 - val_accuracy: 0.5566\n",
            "Epoch 168/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4756 - accuracy: 0.9094 - val_loss: 14.5479 - val_accuracy: 0.4545\n",
            "Epoch 169/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4481 - accuracy: 0.9164 - val_loss: 14.9420 - val_accuracy: 0.5597\n",
            "Epoch 170/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4776 - accuracy: 0.9231 - val_loss: 11.1138 - val_accuracy: 0.4641\n",
            "Epoch 171/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4481 - accuracy: 0.9226 - val_loss: 9.3449 - val_accuracy: 0.4684\n",
            "Epoch 172/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4379 - accuracy: 0.9209 - val_loss: 9.8079 - val_accuracy: 0.4937\n",
            "Epoch 173/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4365 - accuracy: 0.9213 - val_loss: 10.9860 - val_accuracy: 0.4674\n",
            "Epoch 174/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4406 - accuracy: 0.9199 - val_loss: 12.3519 - val_accuracy: 0.5421\n",
            "Epoch 175/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4231 - accuracy: 0.9196 - val_loss: 12.4970 - val_accuracy: 0.5851\n",
            "Epoch 176/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4393 - accuracy: 0.9207 - val_loss: 9.5741 - val_accuracy: 0.5068\n",
            "Epoch 177/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.9564 - accuracy: 0.9058 - val_loss: 16.2508 - val_accuracy: 0.4841\n",
            "Epoch 178/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4432 - accuracy: 0.9157 - val_loss: 15.2701 - val_accuracy: 0.4868\n",
            "Epoch 179/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4364 - accuracy: 0.9187 - val_loss: 15.3195 - val_accuracy: 0.4917\n",
            "Epoch 180/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4373 - accuracy: 0.9171 - val_loss: 13.5136 - val_accuracy: 0.4556\n",
            "Epoch 181/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.8412 - accuracy: 0.9091 - val_loss: 15.3447 - val_accuracy: 0.4783\n",
            "Epoch 182/500\n",
            "124/124 [==============================] - 7s 58ms/step - loss: 0.4373 - accuracy: 0.9194 - val_loss: 12.8608 - val_accuracy: 0.5761\n",
            "Epoch 183/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4279 - accuracy: 0.9214 - val_loss: 11.1284 - val_accuracy: 0.5855\n",
            "Epoch 184/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4217 - accuracy: 0.9212 - val_loss: 11.5568 - val_accuracy: 0.4847\n",
            "Epoch 185/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4456 - accuracy: 0.9159 - val_loss: 9.9831 - val_accuracy: 0.5100\n",
            "Epoch 186/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4242 - accuracy: 0.9217 - val_loss: 9.1481 - val_accuracy: 0.5230\n",
            "Epoch 187/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4333 - accuracy: 0.9187 - val_loss: 8.9386 - val_accuracy: 0.5664\n",
            "Epoch 188/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4416 - accuracy: 0.9156 - val_loss: 12.2238 - val_accuracy: 0.5822\n",
            "Epoch 189/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4295 - accuracy: 0.9226 - val_loss: 10.8211 - val_accuracy: 0.5738\n",
            "Epoch 190/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4311 - accuracy: 0.9244 - val_loss: 9.9015 - val_accuracy: 0.5177\n",
            "Epoch 191/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4327 - accuracy: 0.9226 - val_loss: 10.0973 - val_accuracy: 0.5807\n",
            "Epoch 192/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4364 - accuracy: 0.9233 - val_loss: 11.2832 - val_accuracy: 0.4788\n",
            "Epoch 193/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4465 - accuracy: 0.9223 - val_loss: 10.5382 - val_accuracy: 0.5132\n",
            "Epoch 194/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4459 - accuracy: 0.9147 - val_loss: 13.1740 - val_accuracy: 0.4905\n",
            "Epoch 195/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4543 - accuracy: 0.9156 - val_loss: 11.0565 - val_accuracy: 0.5776\n",
            "Epoch 196/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.5017 - accuracy: 0.8790 - val_loss: 10.4824 - val_accuracy: 0.4662\n",
            "Epoch 197/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4684 - accuracy: 0.8956 - val_loss: 13.8688 - val_accuracy: 0.4970\n",
            "Epoch 198/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4590 - accuracy: 0.9175 - val_loss: 10.0209 - val_accuracy: 0.5004\n",
            "Epoch 199/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4427 - accuracy: 0.9183 - val_loss: 10.3226 - val_accuracy: 0.4759\n",
            "Epoch 200/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4741 - accuracy: 0.9053 - val_loss: 12.4730 - val_accuracy: 0.5159\n",
            "Epoch 201/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4620 - accuracy: 0.9123 - val_loss: 13.9375 - val_accuracy: 0.4851\n",
            "Epoch 202/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4529 - accuracy: 0.9152 - val_loss: 12.3272 - val_accuracy: 0.4537\n",
            "Epoch 203/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.4411 - accuracy: 0.9190 - val_loss: 10.6088 - val_accuracy: 0.5619\n",
            "Epoch 204/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4318 - accuracy: 0.9220 - val_loss: 10.5601 - val_accuracy: 0.5528\n",
            "Epoch 205/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4325 - accuracy: 0.9233 - val_loss: 9.9674 - val_accuracy: 0.4401\n",
            "Epoch 206/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4735 - accuracy: 0.9125 - val_loss: 14.7042 - val_accuracy: 0.5753\n",
            "Epoch 207/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4403 - accuracy: 0.9211 - val_loss: 11.7269 - val_accuracy: 0.5020\n",
            "Epoch 208/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4530 - accuracy: 0.9193 - val_loss: 11.3029 - val_accuracy: 0.5698\n",
            "Epoch 209/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4306 - accuracy: 0.9214 - val_loss: 10.2094 - val_accuracy: 0.5025\n",
            "Epoch 210/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4321 - accuracy: 0.9202 - val_loss: 10.2831 - val_accuracy: 0.5030\n",
            "Epoch 211/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4383 - accuracy: 0.9223 - val_loss: 9.1357 - val_accuracy: 0.5060\n",
            "Epoch 212/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4420 - accuracy: 0.9218 - val_loss: 10.2167 - val_accuracy: 0.4857\n",
            "Epoch 213/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.5200 - accuracy: 0.8978 - val_loss: 9.6461 - val_accuracy: 0.4749\n",
            "Epoch 214/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4643 - accuracy: 0.9033 - val_loss: 11.5846 - val_accuracy: 0.5799\n",
            "Epoch 215/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4996 - accuracy: 0.8958 - val_loss: 10.0732 - val_accuracy: 0.4664\n",
            "Epoch 216/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4659 - accuracy: 0.8990 - val_loss: 10.3000 - val_accuracy: 0.5951\n",
            "Epoch 217/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4678 - accuracy: 0.9058 - val_loss: 11.4628 - val_accuracy: 0.5857\n",
            "Epoch 218/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4517 - accuracy: 0.9124 - val_loss: 14.1416 - val_accuracy: 0.5889\n",
            "Epoch 219/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4592 - accuracy: 0.9153 - val_loss: 10.1290 - val_accuracy: 0.4526\n",
            "Epoch 220/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4360 - accuracy: 0.9199 - val_loss: 9.8334 - val_accuracy: 0.4611\n",
            "Epoch 221/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4391 - accuracy: 0.9177 - val_loss: 8.2213 - val_accuracy: 0.4673\n",
            "Epoch 222/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4314 - accuracy: 0.9208 - val_loss: 8.8028 - val_accuracy: 0.5878\n",
            "Epoch 223/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4370 - accuracy: 0.9217 - val_loss: 9.5960 - val_accuracy: 0.5152\n",
            "Epoch 224/500\n",
            "124/124 [==============================] - 7s 56ms/step - loss: 0.4557 - accuracy: 0.9188 - val_loss: 9.5341 - val_accuracy: 0.5031\n",
            "Epoch 225/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4414 - accuracy: 0.9217 - val_loss: 10.2592 - val_accuracy: 0.4519\n",
            "Epoch 226/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4634 - accuracy: 0.9010 - val_loss: 13.3330 - val_accuracy: 0.5816\n",
            "Epoch 227/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4535 - accuracy: 0.9078 - val_loss: 13.8242 - val_accuracy: 0.5838\n",
            "Epoch 228/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4524 - accuracy: 0.9134 - val_loss: 12.9651 - val_accuracy: 0.4593\n",
            "Epoch 229/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4727 - accuracy: 0.9139 - val_loss: 11.9082 - val_accuracy: 0.4913\n",
            "Epoch 230/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4441 - accuracy: 0.9174 - val_loss: 9.0005 - val_accuracy: 0.5509\n",
            "Epoch 231/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4298 - accuracy: 0.9218 - val_loss: 9.2856 - val_accuracy: 0.4821\n",
            "Epoch 232/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4324 - accuracy: 0.9231 - val_loss: 10.4784 - val_accuracy: 0.5421\n",
            "Epoch 233/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4446 - accuracy: 0.9218 - val_loss: 11.6781 - val_accuracy: 0.4519\n",
            "Epoch 234/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4703 - accuracy: 0.9125 - val_loss: 13.1200 - val_accuracy: 0.5515\n",
            "Epoch 235/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4606 - accuracy: 0.9198 - val_loss: 10.4730 - val_accuracy: 0.5389\n",
            "Epoch 236/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4276 - accuracy: 0.9223 - val_loss: 9.5462 - val_accuracy: 0.4970\n",
            "Epoch 237/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4510 - accuracy: 0.9228 - val_loss: 9.1387 - val_accuracy: 0.5454\n",
            "Epoch 238/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4247 - accuracy: 0.9250 - val_loss: 8.6431 - val_accuracy: 0.4954\n",
            "Epoch 239/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4292 - accuracy: 0.9241 - val_loss: 9.0198 - val_accuracy: 0.4781\n",
            "Epoch 240/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4228 - accuracy: 0.9254 - val_loss: 10.2226 - val_accuracy: 0.5489\n",
            "Epoch 241/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4250 - accuracy: 0.9248 - val_loss: 9.7064 - val_accuracy: 0.4727\n",
            "Epoch 242/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4322 - accuracy: 0.9218 - val_loss: 9.5455 - val_accuracy: 0.5875\n",
            "Epoch 243/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4388 - accuracy: 0.9226 - val_loss: 11.4917 - val_accuracy: 0.5762\n",
            "Epoch 244/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4791 - accuracy: 0.9012 - val_loss: 13.3436 - val_accuracy: 0.5791\n",
            "Epoch 245/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4629 - accuracy: 0.9074 - val_loss: 13.3945 - val_accuracy: 0.4681\n",
            "Epoch 246/500\n",
            "124/124 [==============================] - 7s 55ms/step - loss: 0.4529 - accuracy: 0.9125 - val_loss: 14.7524 - val_accuracy: 0.4778\n",
            "Epoch 247/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4582 - accuracy: 0.9178 - val_loss: 15.3105 - val_accuracy: 0.4786\n",
            "Epoch 248/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4433 - accuracy: 0.9192 - val_loss: 14.5620 - val_accuracy: 0.5673\n",
            "Epoch 249/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4313 - accuracy: 0.9257 - val_loss: 9.8842 - val_accuracy: 0.4900\n",
            "Epoch 250/500\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.4293 - accuracy: 0.9253 - val_loss: 12.2085 - val_accuracy: 0.4835\n",
            "Epoch 251/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4197 - accuracy: 0.9257 - val_loss: 8.9904 - val_accuracy: 0.4391\n",
            "Epoch 252/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4606 - accuracy: 0.9094 - val_loss: 16.1208 - val_accuracy: 0.5192\n",
            "Epoch 253/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4454 - accuracy: 0.9153 - val_loss: 16.4278 - val_accuracy: 0.5763\n",
            "Epoch 254/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4435 - accuracy: 0.9196 - val_loss: 17.7720 - val_accuracy: 0.4804\n",
            "Epoch 255/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4445 - accuracy: 0.9219 - val_loss: 15.4762 - val_accuracy: 0.4743\n",
            "Epoch 256/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4557 - accuracy: 0.9181 - val_loss: 12.7269 - val_accuracy: 0.5671\n",
            "Epoch 257/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4360 - accuracy: 0.9223 - val_loss: 11.7293 - val_accuracy: 0.5684\n",
            "Epoch 258/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4363 - accuracy: 0.9240 - val_loss: 12.2384 - val_accuracy: 0.6071\n",
            "Epoch 259/500\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.4309 - accuracy: 0.9218 - val_loss: 12.2970 - val_accuracy: 0.4903\n",
            "Epoch 260/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4309 - accuracy: 0.9230 - val_loss: 11.9986 - val_accuracy: 0.5801\n",
            "Epoch 261/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5024 - accuracy: 0.9127 - val_loss: 13.4407 - val_accuracy: 0.5488\n",
            "Epoch 262/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5379 - accuracy: 0.8870 - val_loss: 13.6762 - val_accuracy: 0.4623\n",
            "Epoch 263/500\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 0.4732 - accuracy: 0.9021 - val_loss: 15.0689 - val_accuracy: 0.4750\n",
            "Epoch 264/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4632 - accuracy: 0.9058 - val_loss: 15.0379 - val_accuracy: 0.4868\n",
            "Epoch 265/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4816 - accuracy: 0.9045 - val_loss: 14.8247 - val_accuracy: 0.4726\n",
            "Epoch 266/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4638 - accuracy: 0.9060 - val_loss: 14.0181 - val_accuracy: 0.5716\n",
            "Epoch 267/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.4952 - accuracy: 0.9078 - val_loss: 14.7598 - val_accuracy: 0.5699\n",
            "Epoch 268/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4625 - accuracy: 0.9116 - val_loss: 13.3483 - val_accuracy: 0.4726\n",
            "Epoch 269/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5366 - accuracy: 0.9078 - val_loss: 9.9291 - val_accuracy: 0.4666\n",
            "Epoch 270/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4638 - accuracy: 0.9037 - val_loss: 10.6630 - val_accuracy: 0.4678\n",
            "[(0.6258227825164795, 119, 'learning rate :0.1', 'std :1')]\n",
            "Epoch 1/500\n",
            "124/124 [==============================] - 7s 47ms/step - loss: 0.9654 - accuracy: 0.8003 - val_loss: 2.0018 - val_accuracy: 0.5617\n",
            "Epoch 2/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.7820 - accuracy: 0.8406 - val_loss: 3.4811 - val_accuracy: 0.5068\n",
            "Epoch 3/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5309 - accuracy: 0.8515 - val_loss: 4.5871 - val_accuracy: 0.4220\n",
            "Epoch 4/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5723 - accuracy: 0.8628 - val_loss: 3.3081 - val_accuracy: 0.4364\n",
            "Epoch 5/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4669 - accuracy: 0.8912 - val_loss: 4.1041 - val_accuracy: 0.5536\n",
            "Epoch 6/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4695 - accuracy: 0.8889 - val_loss: 3.4049 - val_accuracy: 0.5482\n",
            "Epoch 7/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5419 - accuracy: 0.8665 - val_loss: 3.8567 - val_accuracy: 0.5791\n",
            "Epoch 8/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4749 - accuracy: 0.8809 - val_loss: 4.3955 - val_accuracy: 0.5820\n",
            "Epoch 9/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4999 - accuracy: 0.8816 - val_loss: 3.8011 - val_accuracy: 0.5606\n",
            "Epoch 10/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.5235 - accuracy: 0.8632 - val_loss: 4.8205 - val_accuracy: 0.4761\n",
            "Epoch 11/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.8215 - accuracy: 0.8685 - val_loss: 4.6115 - val_accuracy: 0.5729\n",
            "Epoch 12/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4710 - accuracy: 0.8793 - val_loss: 5.5022 - val_accuracy: 0.4520\n",
            "Epoch 13/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4775 - accuracy: 0.8789 - val_loss: 3.6912 - val_accuracy: 0.5668\n",
            "Epoch 14/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4783 - accuracy: 0.8805 - val_loss: 6.2242 - val_accuracy: 0.5540\n",
            "Epoch 15/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4650 - accuracy: 0.8827 - val_loss: 5.3027 - val_accuracy: 0.4415\n",
            "Epoch 16/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4794 - accuracy: 0.8828 - val_loss: 5.8051 - val_accuracy: 0.4328\n",
            "Epoch 17/500\n",
            "124/124 [==============================] - 7s 60ms/step - loss: 0.4749 - accuracy: 0.8821 - val_loss: 6.1989 - val_accuracy: 0.5579\n",
            "Epoch 18/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4628 - accuracy: 0.8832 - val_loss: 4.6943 - val_accuracy: 0.5682\n",
            "Epoch 19/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4809 - accuracy: 0.8829 - val_loss: 5.0975 - val_accuracy: 0.5558\n",
            "Epoch 20/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4800 - accuracy: 0.8816 - val_loss: 5.0098 - val_accuracy: 0.4484\n",
            "Epoch 21/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4590 - accuracy: 0.8821 - val_loss: 4.6396 - val_accuracy: 0.5681\n",
            "Epoch 22/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4793 - accuracy: 0.8823 - val_loss: 4.7166 - val_accuracy: 0.4328\n",
            "Epoch 23/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.5095 - accuracy: 0.8694 - val_loss: 5.2911 - val_accuracy: 0.5796\n",
            "Epoch 24/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4728 - accuracy: 0.8787 - val_loss: 5.7998 - val_accuracy: 0.5944\n",
            "Epoch 25/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4628 - accuracy: 0.8840 - val_loss: 6.2603 - val_accuracy: 0.4575\n",
            "Epoch 26/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4630 - accuracy: 0.8835 - val_loss: 6.4186 - val_accuracy: 0.4537\n",
            "Epoch 27/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4644 - accuracy: 0.8867 - val_loss: 7.2050 - val_accuracy: 0.5711\n",
            "Epoch 28/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4720 - accuracy: 0.8849 - val_loss: 6.3838 - val_accuracy: 0.4555\n",
            "Epoch 29/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4669 - accuracy: 0.8826 - val_loss: 6.5352 - val_accuracy: 0.5742\n",
            "Epoch 30/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4814 - accuracy: 0.8795 - val_loss: 5.1723 - val_accuracy: 0.4430\n",
            "Epoch 31/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4903 - accuracy: 0.8690 - val_loss: 3.2993 - val_accuracy: 0.4274\n",
            "Epoch 32/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4894 - accuracy: 0.8742 - val_loss: 3.7929 - val_accuracy: 0.4838\n",
            "Epoch 33/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4903 - accuracy: 0.8777 - val_loss: 5.0118 - val_accuracy: 0.4451\n",
            "Epoch 34/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.8904 - accuracy: 0.8714 - val_loss: 6.4836 - val_accuracy: 0.5883\n",
            "Epoch 35/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4834 - accuracy: 0.8792 - val_loss: 5.9061 - val_accuracy: 0.5927\n",
            "Epoch 36/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4690 - accuracy: 0.8834 - val_loss: 6.2253 - val_accuracy: 0.5641\n",
            "Epoch 37/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.4543 - accuracy: 0.8883 - val_loss: 6.6891 - val_accuracy: 0.4832\n",
            "Epoch 38/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.4907 - accuracy: 0.8735 - val_loss: 9.0417 - val_accuracy: 0.4558\n",
            "Epoch 39/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4625 - accuracy: 0.8796 - val_loss: 9.2278 - val_accuracy: 0.5921\n",
            "Epoch 40/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4717 - accuracy: 0.8855 - val_loss: 8.8885 - val_accuracy: 0.4385\n",
            "Epoch 41/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4749 - accuracy: 0.8849 - val_loss: 7.8094 - val_accuracy: 0.5603\n",
            "Epoch 42/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4643 - accuracy: 0.8868 - val_loss: 8.1159 - val_accuracy: 0.6409\n",
            "Epoch 43/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4699 - accuracy: 0.8832 - val_loss: 9.0592 - val_accuracy: 0.5458\n",
            "Epoch 44/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4586 - accuracy: 0.8897 - val_loss: 8.9479 - val_accuracy: 0.4590\n",
            "Epoch 45/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4649 - accuracy: 0.8883 - val_loss: 9.5530 - val_accuracy: 0.5810\n",
            "Epoch 46/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4607 - accuracy: 0.8862 - val_loss: 8.7228 - val_accuracy: 0.4357\n",
            "Epoch 47/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4592 - accuracy: 0.8872 - val_loss: 8.6382 - val_accuracy: 0.4397\n",
            "Epoch 48/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4415 - accuracy: 0.9045 - val_loss: 9.5487 - val_accuracy: 0.5426\n",
            "Epoch 49/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4260 - accuracy: 0.9148 - val_loss: 5.6916 - val_accuracy: 0.4344\n",
            "Epoch 50/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4364 - accuracy: 0.9143 - val_loss: 8.2940 - val_accuracy: 0.4592\n",
            "Epoch 51/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4310 - accuracy: 0.9209 - val_loss: 7.1530 - val_accuracy: 0.4763\n",
            "Epoch 52/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.3846 - accuracy: 0.9304 - val_loss: 9.2436 - val_accuracy: 0.5479\n",
            "Epoch 53/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4555 - accuracy: 0.9041 - val_loss: 8.7402 - val_accuracy: 0.5713\n",
            "Epoch 54/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4461 - accuracy: 0.9106 - val_loss: 7.7924 - val_accuracy: 0.5223\n",
            "Epoch 55/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4505 - accuracy: 0.9131 - val_loss: 8.7791 - val_accuracy: 0.5889\n",
            "Epoch 56/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4319 - accuracy: 0.9140 - val_loss: 10.1656 - val_accuracy: 0.5347\n",
            "Epoch 57/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4314 - accuracy: 0.9110 - val_loss: 7.3711 - val_accuracy: 0.6550\n",
            "Epoch 58/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.4287 - accuracy: 0.9135 - val_loss: 8.7882 - val_accuracy: 0.6592\n",
            "Epoch 59/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4285 - accuracy: 0.9149 - val_loss: 9.5295 - val_accuracy: 0.5384\n",
            "Epoch 60/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4315 - accuracy: 0.9149 - val_loss: 10.2770 - val_accuracy: 0.5336\n",
            "Epoch 61/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4262 - accuracy: 0.9166 - val_loss: 10.7674 - val_accuracy: 0.5441\n",
            "Epoch 62/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4251 - accuracy: 0.9170 - val_loss: 10.4569 - val_accuracy: 0.5446\n",
            "Epoch 63/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4677 - accuracy: 0.9110 - val_loss: 10.7417 - val_accuracy: 0.6617\n",
            "Epoch 64/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4396 - accuracy: 0.9093 - val_loss: 9.5426 - val_accuracy: 0.5212\n",
            "Epoch 65/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4293 - accuracy: 0.9112 - val_loss: 10.5692 - val_accuracy: 0.6571\n",
            "Epoch 66/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4743 - accuracy: 0.9008 - val_loss: 10.2724 - val_accuracy: 0.6316\n",
            "Epoch 67/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4364 - accuracy: 0.9085 - val_loss: 9.5210 - val_accuracy: 0.5315\n",
            "Epoch 68/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4364 - accuracy: 0.9126 - val_loss: 10.0667 - val_accuracy: 0.6552\n",
            "Epoch 69/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4851 - accuracy: 0.9139 - val_loss: 10.9640 - val_accuracy: 0.6523\n",
            "Epoch 70/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4261 - accuracy: 0.9183 - val_loss: 11.8035 - val_accuracy: 0.6539\n",
            "Epoch 71/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4336 - accuracy: 0.9163 - val_loss: 12.7048 - val_accuracy: 0.6591\n",
            "Epoch 72/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4247 - accuracy: 0.9179 - val_loss: 13.4623 - val_accuracy: 0.4687\n",
            "Epoch 73/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4496 - accuracy: 0.9166 - val_loss: 9.9291 - val_accuracy: 0.6640\n",
            "Epoch 74/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4265 - accuracy: 0.9132 - val_loss: 12.3765 - val_accuracy: 0.6369\n",
            "Epoch 75/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4177 - accuracy: 0.9197 - val_loss: 13.0763 - val_accuracy: 0.5386\n",
            "Epoch 76/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.8960 - accuracy: 0.9089 - val_loss: 14.3175 - val_accuracy: 0.6146\n",
            "Epoch 77/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.5191 - accuracy: 0.9099 - val_loss: 13.9325 - val_accuracy: 0.5910\n",
            "Epoch 78/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.4176 - accuracy: 0.9164 - val_loss: 12.4676 - val_accuracy: 0.5889\n",
            "Epoch 79/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4200 - accuracy: 0.9194 - val_loss: 12.0014 - val_accuracy: 0.5830\n",
            "Epoch 80/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4205 - accuracy: 0.9163 - val_loss: 12.1823 - val_accuracy: 0.4931\n",
            "Epoch 81/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4174 - accuracy: 0.9173 - val_loss: 12.3741 - val_accuracy: 0.4793\n",
            "Epoch 82/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4189 - accuracy: 0.9193 - val_loss: 12.7593 - val_accuracy: 0.4822\n",
            "Epoch 83/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4148 - accuracy: 0.9179 - val_loss: 13.9606 - val_accuracy: 0.5949\n",
            "Epoch 84/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4145 - accuracy: 0.9170 - val_loss: 15.0420 - val_accuracy: 0.5961\n",
            "Epoch 85/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4416 - accuracy: 0.9165 - val_loss: 12.9397 - val_accuracy: 0.4850\n",
            "Epoch 86/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4106 - accuracy: 0.9193 - val_loss: 12.4119 - val_accuracy: 0.6453\n",
            "Epoch 87/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4293 - accuracy: 0.9146 - val_loss: 6.8869 - val_accuracy: 0.6380\n",
            "Epoch 88/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4228 - accuracy: 0.9170 - val_loss: 11.8204 - val_accuracy: 0.4996\n",
            "Epoch 89/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4226 - accuracy: 0.9204 - val_loss: 11.0570 - val_accuracy: 0.5338\n",
            "Epoch 90/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4276 - accuracy: 0.9171 - val_loss: 10.7879 - val_accuracy: 0.5403\n",
            "Epoch 91/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3944 - accuracy: 0.9222 - val_loss: 11.7242 - val_accuracy: 0.6428\n",
            "Epoch 92/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.5820 - accuracy: 0.9180 - val_loss: 11.9985 - val_accuracy: 0.4838\n",
            "Epoch 93/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4248 - accuracy: 0.9164 - val_loss: 12.0700 - val_accuracy: 0.5924\n",
            "Epoch 94/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4120 - accuracy: 0.9193 - val_loss: 11.0437 - val_accuracy: 0.6235\n",
            "Epoch 95/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4298 - accuracy: 0.9168 - val_loss: 9.3879 - val_accuracy: 0.6264\n",
            "Epoch 96/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4313 - accuracy: 0.9149 - val_loss: 11.5552 - val_accuracy: 0.6366\n",
            "Epoch 97/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4270 - accuracy: 0.9145 - val_loss: 14.1537 - val_accuracy: 0.6465\n",
            "Epoch 98/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4658 - accuracy: 0.9109 - val_loss: 8.9457 - val_accuracy: 0.5438\n",
            "Epoch 99/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.8181 - accuracy: 0.9041 - val_loss: 8.5815 - val_accuracy: 0.5371\n",
            "Epoch 100/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4278 - accuracy: 0.9128 - val_loss: 9.0114 - val_accuracy: 0.6516\n",
            "Epoch 101/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4376 - accuracy: 0.9129 - val_loss: 11.0700 - val_accuracy: 0.6560\n",
            "Epoch 102/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4207 - accuracy: 0.9150 - val_loss: 11.2766 - val_accuracy: 0.6434\n",
            "Epoch 103/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4351 - accuracy: 0.9147 - val_loss: 12.8279 - val_accuracy: 0.6378\n",
            "Epoch 104/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4189 - accuracy: 0.9152 - val_loss: 13.7894 - val_accuracy: 0.6237\n",
            "Epoch 105/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4356 - accuracy: 0.9139 - val_loss: 13.3739 - val_accuracy: 0.6484\n",
            "Epoch 106/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4231 - accuracy: 0.9186 - val_loss: 12.3073 - val_accuracy: 0.6466\n",
            "Epoch 107/500\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.4186 - accuracy: 0.9186 - val_loss: 12.3288 - val_accuracy: 0.6495\n",
            "Epoch 108/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4218 - accuracy: 0.9203 - val_loss: 13.8657 - val_accuracy: 0.5288\n",
            "Epoch 109/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4338 - accuracy: 0.9184 - val_loss: 12.4176 - val_accuracy: 0.5572\n",
            "Epoch 110/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4166 - accuracy: 0.9215 - val_loss: 13.1065 - val_accuracy: 0.5241\n",
            "Epoch 111/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4089 - accuracy: 0.9260 - val_loss: 10.8446 - val_accuracy: 0.6905\n",
            "Epoch 112/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4046 - accuracy: 0.9244 - val_loss: 11.1874 - val_accuracy: 0.5478\n",
            "Epoch 113/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4450 - accuracy: 0.9164 - val_loss: 12.0129 - val_accuracy: 0.6587\n",
            "Epoch 114/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4280 - accuracy: 0.9177 - val_loss: 12.9289 - val_accuracy: 0.5238\n",
            "Epoch 115/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4214 - accuracy: 0.9162 - val_loss: 11.3549 - val_accuracy: 0.6609\n",
            "Epoch 116/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4217 - accuracy: 0.9192 - val_loss: 12.7882 - val_accuracy: 0.5524\n",
            "Epoch 117/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4147 - accuracy: 0.9186 - val_loss: 14.1735 - val_accuracy: 0.6685\n",
            "Epoch 118/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4387 - accuracy: 0.9210 - val_loss: 13.2287 - val_accuracy: 0.6593\n",
            "Epoch 119/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.4327 - accuracy: 0.9117 - val_loss: 9.1763 - val_accuracy: 0.5401\n",
            "Epoch 120/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.4250 - accuracy: 0.9138 - val_loss: 13.3589 - val_accuracy: 0.6400\n",
            "Epoch 121/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4143 - accuracy: 0.9222 - val_loss: 13.6301 - val_accuracy: 0.6505\n",
            "Epoch 122/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4186 - accuracy: 0.9223 - val_loss: 11.4291 - val_accuracy: 0.6495\n",
            "Epoch 123/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4031 - accuracy: 0.9256 - val_loss: 12.4202 - val_accuracy: 0.6214\n",
            "Epoch 124/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3984 - accuracy: 0.9264 - val_loss: 11.1096 - val_accuracy: 0.5676\n",
            "Epoch 125/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4207 - accuracy: 0.9219 - val_loss: 12.4792 - val_accuracy: 0.5266\n",
            "Epoch 126/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4096 - accuracy: 0.9246 - val_loss: 11.4282 - val_accuracy: 0.5006\n",
            "Epoch 127/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3974 - accuracy: 0.9270 - val_loss: 10.8550 - val_accuracy: 0.6255\n",
            "Epoch 128/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4177 - accuracy: 0.9238 - val_loss: 10.3122 - val_accuracy: 0.5316\n",
            "Epoch 129/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4369 - accuracy: 0.9192 - val_loss: 11.8091 - val_accuracy: 0.6397\n",
            "Epoch 130/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4118 - accuracy: 0.9204 - val_loss: 13.1336 - val_accuracy: 0.5388\n",
            "Epoch 131/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4312 - accuracy: 0.9189 - val_loss: 11.5970 - val_accuracy: 0.6698\n",
            "Epoch 132/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4202 - accuracy: 0.9185 - val_loss: 12.3945 - val_accuracy: 0.5549\n",
            "Epoch 133/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4162 - accuracy: 0.9199 - val_loss: 12.6901 - val_accuracy: 0.6786\n",
            "Epoch 134/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4465 - accuracy: 0.9179 - val_loss: 13.7786 - val_accuracy: 0.6637\n",
            "Epoch 135/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4279 - accuracy: 0.9202 - val_loss: 10.5219 - val_accuracy: 0.5402\n",
            "Epoch 136/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4414 - accuracy: 0.9156 - val_loss: 11.7247 - val_accuracy: 0.6559\n",
            "Epoch 137/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4197 - accuracy: 0.9204 - val_loss: 11.8319 - val_accuracy: 0.5438\n",
            "Epoch 138/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4318 - accuracy: 0.9197 - val_loss: 13.9275 - val_accuracy: 0.6386\n",
            "Epoch 139/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4328 - accuracy: 0.9239 - val_loss: 12.6580 - val_accuracy: 0.6311\n",
            "Epoch 140/500\n",
            "124/124 [==============================] - 8s 62ms/step - loss: 0.3783 - accuracy: 0.9157 - val_loss: 10.5299 - val_accuracy: 0.5848\n",
            "Epoch 141/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3771 - accuracy: 0.9188 - val_loss: 13.4116 - val_accuracy: 0.5216\n",
            "Epoch 142/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4364 - accuracy: 0.9177 - val_loss: 13.6480 - val_accuracy: 0.5034\n",
            "Epoch 143/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4281 - accuracy: 0.9184 - val_loss: 14.2441 - val_accuracy: 0.6509\n",
            "Epoch 144/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4215 - accuracy: 0.9177 - val_loss: 14.7744 - val_accuracy: 0.5361\n",
            "Epoch 145/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4681 - accuracy: 0.9020 - val_loss: 18.7919 - val_accuracy: 0.5896\n",
            "Epoch 146/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4509 - accuracy: 0.9093 - val_loss: 20.9593 - val_accuracy: 0.6035\n",
            "Epoch 147/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4289 - accuracy: 0.9144 - val_loss: 21.9866 - val_accuracy: 0.5830\n",
            "Epoch 148/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4393 - accuracy: 0.9137 - val_loss: 19.8098 - val_accuracy: 0.6096\n",
            "Epoch 149/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4768 - accuracy: 0.9160 - val_loss: 20.0790 - val_accuracy: 0.6331\n",
            "Epoch 150/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3969 - accuracy: 0.9283 - val_loss: 20.3002 - val_accuracy: 0.5688\n",
            "Epoch 151/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3944 - accuracy: 0.9318 - val_loss: 23.8410 - val_accuracy: 0.4898\n",
            "Epoch 152/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3912 - accuracy: 0.9322 - val_loss: 21.6658 - val_accuracy: 0.5686\n",
            "Epoch 153/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3808 - accuracy: 0.9325 - val_loss: 22.8000 - val_accuracy: 0.6354\n",
            "Epoch 154/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.5027 - accuracy: 0.9178 - val_loss: 23.8423 - val_accuracy: 0.5327\n",
            "Epoch 155/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4246 - accuracy: 0.9155 - val_loss: 23.7462 - val_accuracy: 0.5346\n",
            "Epoch 156/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4244 - accuracy: 0.9148 - val_loss: 24.4935 - val_accuracy: 0.5283\n",
            "Epoch 157/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4220 - accuracy: 0.9199 - val_loss: 25.7830 - val_accuracy: 0.5483\n",
            "Epoch 158/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4261 - accuracy: 0.9205 - val_loss: 25.8121 - val_accuracy: 0.5593\n",
            "Epoch 159/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4155 - accuracy: 0.9186 - val_loss: 25.5930 - val_accuracy: 0.5484\n",
            "Epoch 160/500\n",
            "124/124 [==============================] - 8s 62ms/step - loss: 0.4381 - accuracy: 0.9188 - val_loss: 21.8966 - val_accuracy: 0.6528\n",
            "Epoch 161/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4290 - accuracy: 0.9212 - val_loss: 23.3477 - val_accuracy: 0.5513\n",
            "Epoch 162/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4207 - accuracy: 0.9218 - val_loss: 15.0110 - val_accuracy: 0.6093\n",
            "Epoch 163/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4624 - accuracy: 0.9167 - val_loss: 16.4267 - val_accuracy: 0.6430\n",
            "Epoch 164/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4189 - accuracy: 0.9318 - val_loss: 16.6590 - val_accuracy: 0.6503\n",
            "Epoch 165/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4184 - accuracy: 0.9334 - val_loss: 17.9955 - val_accuracy: 0.5262\n",
            "Epoch 166/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4034 - accuracy: 0.9348 - val_loss: 19.1585 - val_accuracy: 0.5349\n",
            "Epoch 167/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3954 - accuracy: 0.9339 - val_loss: 20.7560 - val_accuracy: 0.6408\n",
            "Epoch 168/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4031 - accuracy: 0.9382 - val_loss: 20.5218 - val_accuracy: 0.5430\n",
            "Epoch 169/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3846 - accuracy: 0.9336 - val_loss: 21.0703 - val_accuracy: 0.6099\n",
            "Epoch 170/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4306 - accuracy: 0.9370 - val_loss: 20.9434 - val_accuracy: 0.5616\n",
            "Epoch 171/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4593 - accuracy: 0.9352 - val_loss: 17.2180 - val_accuracy: 0.5327\n",
            "Epoch 172/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4245 - accuracy: 0.9201 - val_loss: 19.0641 - val_accuracy: 0.5161\n",
            "Epoch 173/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4070 - accuracy: 0.9271 - val_loss: 19.7052 - val_accuracy: 0.6312\n",
            "Epoch 174/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4040 - accuracy: 0.9335 - val_loss: 20.3341 - val_accuracy: 0.5988\n",
            "Epoch 175/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3860 - accuracy: 0.9364 - val_loss: 18.2246 - val_accuracy: 0.6132\n",
            "Epoch 176/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3922 - accuracy: 0.9387 - val_loss: 17.2561 - val_accuracy: 0.5308\n",
            "Epoch 177/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.9071 - accuracy: 0.9153 - val_loss: 18.5779 - val_accuracy: 0.5732\n",
            "Epoch 178/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3238 - accuracy: 0.9210 - val_loss: 17.2636 - val_accuracy: 0.5910\n",
            "Epoch 179/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3221 - accuracy: 0.9215 - val_loss: 19.1872 - val_accuracy: 0.4848\n",
            "Epoch 180/500\n",
            "124/124 [==============================] - 8s 62ms/step - loss: 0.3456 - accuracy: 0.9202 - val_loss: 19.3641 - val_accuracy: 0.5998\n",
            "Epoch 181/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.7191 - accuracy: 0.9169 - val_loss: 17.1437 - val_accuracy: 0.6397\n",
            "Epoch 182/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.5345 - accuracy: 0.9138 - val_loss: 13.9508 - val_accuracy: 0.5299\n",
            "Epoch 183/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.2798 - accuracy: 0.9135 - val_loss: 13.1634 - val_accuracy: 0.6255\n",
            "Epoch 184/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4006 - accuracy: 0.9158 - val_loss: 13.8419 - val_accuracy: 0.5584\n",
            "Epoch 185/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2648 - accuracy: 0.9179 - val_loss: 14.6845 - val_accuracy: 0.5500\n",
            "Epoch 186/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3063 - accuracy: 0.9186 - val_loss: 13.8482 - val_accuracy: 0.5868\n",
            "Epoch 187/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2865 - accuracy: 0.9120 - val_loss: 14.5494 - val_accuracy: 0.5137\n",
            "Epoch 188/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3047 - accuracy: 0.9170 - val_loss: 15.0686 - val_accuracy: 0.5349\n",
            "Epoch 189/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2746 - accuracy: 0.9176 - val_loss: 14.4865 - val_accuracy: 0.5567\n",
            "Epoch 190/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2947 - accuracy: 0.9207 - val_loss: 13.2110 - val_accuracy: 0.5489\n",
            "Epoch 191/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2372 - accuracy: 0.9202 - val_loss: 15.2953 - val_accuracy: 0.5320\n",
            "Epoch 192/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3098 - accuracy: 0.9204 - val_loss: 14.8177 - val_accuracy: 0.5346\n",
            "Epoch 193/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2766 - accuracy: 0.9213 - val_loss: 16.0120 - val_accuracy: 0.5344\n",
            "Epoch 194/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2749 - accuracy: 0.9202 - val_loss: 15.8279 - val_accuracy: 0.5060\n",
            "Epoch 195/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2584 - accuracy: 0.9226 - val_loss: 14.6804 - val_accuracy: 0.5424\n",
            "Epoch 196/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2417 - accuracy: 0.9233 - val_loss: 16.1424 - val_accuracy: 0.5368\n",
            "Epoch 197/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2544 - accuracy: 0.9263 - val_loss: 16.4635 - val_accuracy: 0.5235\n",
            "Epoch 198/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2717 - accuracy: 0.9237 - val_loss: 16.8479 - val_accuracy: 0.5263\n",
            "Epoch 199/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2321 - accuracy: 0.9244 - val_loss: 16.2624 - val_accuracy: 0.5208\n",
            "Epoch 200/500\n",
            "124/124 [==============================] - 8s 62ms/step - loss: 0.2598 - accuracy: 0.9239 - val_loss: 16.4177 - val_accuracy: 0.5585\n",
            "Epoch 201/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2762 - accuracy: 0.9224 - val_loss: 18.3476 - val_accuracy: 0.5807\n",
            "Epoch 202/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2319 - accuracy: 0.9261 - val_loss: 11.2462 - val_accuracy: 0.6107\n",
            "Epoch 203/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2762 - accuracy: 0.9183 - val_loss: 14.5086 - val_accuracy: 0.5744\n",
            "Epoch 204/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4096 - accuracy: 0.9238 - val_loss: 17.3974 - val_accuracy: 0.5676\n",
            "Epoch 205/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2901 - accuracy: 0.9198 - val_loss: 17.6423 - val_accuracy: 0.6305\n",
            "Epoch 206/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2591 - accuracy: 0.9210 - val_loss: 23.8898 - val_accuracy: 0.5803\n",
            "Epoch 207/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2619 - accuracy: 0.9281 - val_loss: 23.3234 - val_accuracy: 0.5493\n",
            "Epoch 208/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3012 - accuracy: 0.9221 - val_loss: 25.3752 - val_accuracy: 0.5672\n",
            "Epoch 209/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3368 - accuracy: 0.9199 - val_loss: 21.1029 - val_accuracy: 0.6024\n",
            "Epoch 210/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2568 - accuracy: 0.9206 - val_loss: 24.4444 - val_accuracy: 0.6208\n",
            "Epoch 211/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2337 - accuracy: 0.9237 - val_loss: 24.9702 - val_accuracy: 0.5660\n",
            "Epoch 212/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2790 - accuracy: 0.9273 - val_loss: 15.6724 - val_accuracy: 0.5528\n",
            "Epoch 213/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2612 - accuracy: 0.9204 - val_loss: 21.9320 - val_accuracy: 0.5711\n",
            "Epoch 214/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2410 - accuracy: 0.9259 - val_loss: 27.7076 - val_accuracy: 0.5974\n",
            "Epoch 215/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2304 - accuracy: 0.9290 - val_loss: 26.3359 - val_accuracy: 0.5622\n",
            "Epoch 216/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2504 - accuracy: 0.9265 - val_loss: 28.0722 - val_accuracy: 0.5717\n",
            "Epoch 217/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2405 - accuracy: 0.9269 - val_loss: 25.6737 - val_accuracy: 0.5708\n",
            "Epoch 218/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3024 - accuracy: 0.9245 - val_loss: 26.5597 - val_accuracy: 0.5713\n",
            "Epoch 219/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2440 - accuracy: 0.9290 - val_loss: 30.0004 - val_accuracy: 0.5570\n",
            "Epoch 220/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.2386 - accuracy: 0.9258 - val_loss: 29.8839 - val_accuracy: 0.5792\n",
            "Epoch 221/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2527 - accuracy: 0.9270 - val_loss: 29.7151 - val_accuracy: 0.5707\n",
            "Epoch 222/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2262 - accuracy: 0.9261 - val_loss: 25.5630 - val_accuracy: 0.5959\n",
            "Epoch 223/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2783 - accuracy: 0.9250 - val_loss: 27.8441 - val_accuracy: 0.6283\n",
            "Epoch 224/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2756 - accuracy: 0.9281 - val_loss: 27.2649 - val_accuracy: 0.5666\n",
            "Epoch 225/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2368 - accuracy: 0.9262 - val_loss: 30.0454 - val_accuracy: 0.5819\n",
            "Epoch 226/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4726 - accuracy: 0.9258 - val_loss: 26.2087 - val_accuracy: 0.5743\n",
            "Epoch 227/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2937 - accuracy: 0.9220 - val_loss: 31.9980 - val_accuracy: 0.5824\n",
            "Epoch 228/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3810 - accuracy: 0.9210 - val_loss: 28.8177 - val_accuracy: 0.6321\n",
            "Epoch 229/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3561 - accuracy: 0.9171 - val_loss: 28.4102 - val_accuracy: 0.6010\n",
            "Epoch 230/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3175 - accuracy: 0.9038 - val_loss: 30.5430 - val_accuracy: 0.6159\n",
            "Epoch 231/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2771 - accuracy: 0.9063 - val_loss: 38.6619 - val_accuracy: 0.5940\n",
            "Epoch 232/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.7411 - accuracy: 0.9127 - val_loss: 27.3716 - val_accuracy: 0.6019\n",
            "Epoch 233/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3198 - accuracy: 0.9085 - val_loss: 29.5246 - val_accuracy: 0.5752\n",
            "Epoch 234/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2835 - accuracy: 0.9116 - val_loss: 29.9834 - val_accuracy: 0.6230\n",
            "Epoch 235/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2532 - accuracy: 0.9152 - val_loss: 33.6699 - val_accuracy: 0.5907\n",
            "Epoch 236/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2612 - accuracy: 0.9174 - val_loss: 30.7801 - val_accuracy: 0.5936\n",
            "Epoch 237/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.6231 - accuracy: 0.9031 - val_loss: 33.8895 - val_accuracy: 0.5547\n",
            "Epoch 238/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3561 - accuracy: 0.9156 - val_loss: 34.8186 - val_accuracy: 0.5726\n",
            "Epoch 239/500\n",
            "124/124 [==============================] - 7s 60ms/step - loss: 0.2876 - accuracy: 0.9162 - val_loss: 38.6915 - val_accuracy: 0.6056\n",
            "Epoch 240/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2531 - accuracy: 0.9165 - val_loss: 38.4564 - val_accuracy: 0.5824\n",
            "Epoch 241/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2345 - accuracy: 0.9205 - val_loss: 38.9793 - val_accuracy: 0.6005\n",
            "Epoch 242/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2740 - accuracy: 0.9186 - val_loss: 37.9072 - val_accuracy: 0.5749\n",
            "Epoch 243/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2585 - accuracy: 0.9206 - val_loss: 38.3870 - val_accuracy: 0.5862\n",
            "Epoch 244/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2741 - accuracy: 0.9231 - val_loss: 40.3139 - val_accuracy: 0.5796\n",
            "Epoch 245/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2678 - accuracy: 0.9222 - val_loss: 37.2561 - val_accuracy: 0.5768\n",
            "Epoch 246/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2555 - accuracy: 0.9217 - val_loss: 37.7201 - val_accuracy: 0.6162\n",
            "Epoch 247/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2693 - accuracy: 0.9243 - val_loss: 37.1467 - val_accuracy: 0.5862\n",
            "Epoch 248/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2624 - accuracy: 0.9215 - val_loss: 34.9924 - val_accuracy: 0.5827\n",
            "Epoch 249/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2300 - accuracy: 0.9249 - val_loss: 38.8996 - val_accuracy: 0.5608\n",
            "Epoch 250/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2635 - accuracy: 0.9253 - val_loss: 36.3715 - val_accuracy: 0.5668\n",
            "Epoch 251/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2372 - accuracy: 0.9241 - val_loss: 37.5913 - val_accuracy: 0.5710\n",
            "Epoch 252/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2159 - accuracy: 0.9245 - val_loss: 37.4683 - val_accuracy: 0.6026\n",
            "Epoch 253/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3419 - accuracy: 0.9183 - val_loss: 40.7077 - val_accuracy: 0.6328\n",
            "Epoch 254/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3126 - accuracy: 0.9257 - val_loss: 40.2409 - val_accuracy: 0.5749\n",
            "Epoch 255/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2811 - accuracy: 0.9250 - val_loss: 44.0688 - val_accuracy: 0.5860\n",
            "Epoch 256/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2844 - accuracy: 0.9249 - val_loss: 43.1201 - val_accuracy: 0.5980\n",
            "Epoch 257/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2556 - accuracy: 0.9254 - val_loss: 41.4227 - val_accuracy: 0.5807\n",
            "Epoch 258/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2510 - accuracy: 0.9254 - val_loss: 43.7229 - val_accuracy: 0.5829\n",
            "Epoch 259/500\n",
            "124/124 [==============================] - 8s 63ms/step - loss: 0.2335 - accuracy: 0.9243 - val_loss: 37.6645 - val_accuracy: 0.5787\n",
            "Epoch 260/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2632 - accuracy: 0.9272 - val_loss: 39.5760 - val_accuracy: 0.5708\n",
            "Epoch 261/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.2615 - accuracy: 0.9263 - val_loss: 38.5571 - val_accuracy: 0.5755\n",
            "[(0.6258227825164795, 119, 'learning rate :0.1', 'std :1'), (0.6905485391616821, 110, 'learning rate :0.1', 'std :0.1')]\n",
            "Epoch 1/500\n",
            "124/124 [==============================] - 7s 49ms/step - loss: 0.7898 - accuracy: 0.8161 - val_loss: 2.1784 - val_accuracy: 0.5554\n",
            "Epoch 2/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.6346 - accuracy: 0.8500 - val_loss: 2.4514 - val_accuracy: 0.5545\n",
            "Epoch 3/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.6707 - accuracy: 0.8754 - val_loss: 3.0158 - val_accuracy: 0.5099\n",
            "Epoch 4/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4557 - accuracy: 0.8758 - val_loss: 3.7430 - val_accuracy: 0.4890\n",
            "Epoch 5/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4232 - accuracy: 0.8814 - val_loss: 4.3942 - val_accuracy: 0.5087\n",
            "Epoch 6/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4462 - accuracy: 0.8794 - val_loss: 4.1907 - val_accuracy: 0.5750\n",
            "Epoch 7/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4738 - accuracy: 0.8807 - val_loss: 3.8442 - val_accuracy: 0.5900\n",
            "Epoch 8/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.5465 - accuracy: 0.8778 - val_loss: 3.7745 - val_accuracy: 0.5748\n",
            "Epoch 9/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4293 - accuracy: 0.8805 - val_loss: 4.1916 - val_accuracy: 0.5834\n",
            "Epoch 10/500\n",
            "124/124 [==============================] - 8s 63ms/step - loss: 0.4321 - accuracy: 0.8742 - val_loss: 5.5762 - val_accuracy: 0.4882\n",
            "Epoch 11/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.9629 - accuracy: 0.8702 - val_loss: 5.3779 - val_accuracy: 0.4986\n",
            "Epoch 12/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.5676 - accuracy: 0.8706 - val_loss: 7.4308 - val_accuracy: 0.4831\n",
            "Epoch 13/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4673 - accuracy: 0.8715 - val_loss: 3.9700 - val_accuracy: 0.4403\n",
            "Epoch 14/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4700 - accuracy: 0.8556 - val_loss: 4.3562 - val_accuracy: 0.4522\n",
            "Epoch 15/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4456 - accuracy: 0.8628 - val_loss: 4.9828 - val_accuracy: 0.4914\n",
            "Epoch 16/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4358 - accuracy: 0.8807 - val_loss: 6.5339 - val_accuracy: 0.4444\n",
            "Epoch 17/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4264 - accuracy: 0.8817 - val_loss: 6.6034 - val_accuracy: 0.5601\n",
            "Epoch 18/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4151 - accuracy: 0.8842 - val_loss: 7.3613 - val_accuracy: 0.5225\n",
            "Epoch 19/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4266 - accuracy: 0.8851 - val_loss: 6.5513 - val_accuracy: 0.4610\n",
            "Epoch 20/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4495 - accuracy: 0.8818 - val_loss: 5.5023 - val_accuracy: 0.4625\n",
            "Epoch 21/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4969 - accuracy: 0.8700 - val_loss: 6.0295 - val_accuracy: 0.4911\n",
            "Epoch 22/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4272 - accuracy: 0.8811 - val_loss: 5.3758 - val_accuracy: 0.4731\n",
            "Epoch 23/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4281 - accuracy: 0.8884 - val_loss: 4.4793 - val_accuracy: 0.5269\n",
            "Epoch 24/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4447 - accuracy: 0.8739 - val_loss: 5.8726 - val_accuracy: 0.5111\n",
            "Epoch 25/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4205 - accuracy: 0.8794 - val_loss: 6.1333 - val_accuracy: 0.4987\n",
            "Epoch 26/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4200 - accuracy: 0.8812 - val_loss: 6.5851 - val_accuracy: 0.4997\n",
            "Epoch 27/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4207 - accuracy: 0.8815 - val_loss: 7.5564 - val_accuracy: 0.4965\n",
            "Epoch 28/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4225 - accuracy: 0.8848 - val_loss: 7.8747 - val_accuracy: 0.4854\n",
            "Epoch 29/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4155 - accuracy: 0.8863 - val_loss: 8.0263 - val_accuracy: 0.6214\n",
            "Epoch 30/500\n",
            "124/124 [==============================] - 8s 64ms/step - loss: 0.4084 - accuracy: 0.8865 - val_loss: 8.2537 - val_accuracy: 0.5276\n",
            "Epoch 31/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4084 - accuracy: 0.8865 - val_loss: 8.0408 - val_accuracy: 0.5532\n",
            "Epoch 32/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4098 - accuracy: 0.8882 - val_loss: 8.3119 - val_accuracy: 0.5417\n",
            "Epoch 33/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4285 - accuracy: 0.8869 - val_loss: 8.2558 - val_accuracy: 0.4853\n",
            "Epoch 34/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.7448 - accuracy: 0.8835 - val_loss: 7.9508 - val_accuracy: 0.5499\n",
            "Epoch 35/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4076 - accuracy: 0.8890 - val_loss: 7.5776 - val_accuracy: 0.5900\n",
            "Epoch 36/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4089 - accuracy: 0.8894 - val_loss: 7.4170 - val_accuracy: 0.4835\n",
            "Epoch 37/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4301 - accuracy: 0.8858 - val_loss: 5.6347 - val_accuracy: 0.4749\n",
            "Epoch 38/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4087 - accuracy: 0.8942 - val_loss: 5.3134 - val_accuracy: 0.5209\n",
            "Epoch 39/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4202 - accuracy: 0.8893 - val_loss: 5.2967 - val_accuracy: 0.5954\n",
            "Epoch 40/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.4298 - accuracy: 0.8796 - val_loss: 5.6051 - val_accuracy: 0.4844\n",
            "Epoch 41/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.4242 - accuracy: 0.8846 - val_loss: 6.0371 - val_accuracy: 0.4958\n",
            "Epoch 42/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4240 - accuracy: 0.8853 - val_loss: 6.4767 - val_accuracy: 0.4528\n",
            "Epoch 43/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4341 - accuracy: 0.8774 - val_loss: 6.5207 - val_accuracy: 0.5866\n",
            "Epoch 44/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4227 - accuracy: 0.8848 - val_loss: 5.8855 - val_accuracy: 0.4999\n",
            "Epoch 45/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4309 - accuracy: 0.8807 - val_loss: 6.6880 - val_accuracy: 0.5986\n",
            "Epoch 46/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4077 - accuracy: 0.8874 - val_loss: 6.5325 - val_accuracy: 0.4949\n",
            "Epoch 47/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4030 - accuracy: 0.8881 - val_loss: 6.1163 - val_accuracy: 0.4927\n",
            "Epoch 48/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3982 - accuracy: 0.8880 - val_loss: 6.7879 - val_accuracy: 0.5095\n",
            "Epoch 49/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.4045 - accuracy: 0.8863 - val_loss: 6.6902 - val_accuracy: 0.5036\n",
            "Epoch 50/500\n",
            "124/124 [==============================] - 7s 58ms/step - loss: 0.4128 - accuracy: 0.8865 - val_loss: 7.4004 - val_accuracy: 0.5095\n",
            "Epoch 51/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4130 - accuracy: 0.8892 - val_loss: 6.0637 - val_accuracy: 0.5084\n",
            "Epoch 52/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3952 - accuracy: 0.8900 - val_loss: 6.8846 - val_accuracy: 0.5086\n",
            "Epoch 53/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4014 - accuracy: 0.8902 - val_loss: 7.7751 - val_accuracy: 0.5582\n",
            "Epoch 54/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4075 - accuracy: 0.8920 - val_loss: 7.7987 - val_accuracy: 0.4702\n",
            "Epoch 55/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4187 - accuracy: 0.8936 - val_loss: 8.4122 - val_accuracy: 0.5744\n",
            "Epoch 56/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4041 - accuracy: 0.8915 - val_loss: 6.9495 - val_accuracy: 0.4695\n",
            "Epoch 57/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3972 - accuracy: 0.8917 - val_loss: 7.4903 - val_accuracy: 0.5638\n",
            "Epoch 58/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3928 - accuracy: 0.8932 - val_loss: 7.9473 - val_accuracy: 0.4949\n",
            "Epoch 59/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4044 - accuracy: 0.8920 - val_loss: 7.1166 - val_accuracy: 0.5033\n",
            "Epoch 60/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4132 - accuracy: 0.8928 - val_loss: 7.0742 - val_accuracy: 0.5153\n",
            "Epoch 61/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3998 - accuracy: 0.8936 - val_loss: 7.8875 - val_accuracy: 0.4726\n",
            "Epoch 62/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3951 - accuracy: 0.8941 - val_loss: 7.4938 - val_accuracy: 0.4880\n",
            "Epoch 63/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4018 - accuracy: 0.8954 - val_loss: 8.8213 - val_accuracy: 0.4861\n",
            "Epoch 64/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3946 - accuracy: 0.8959 - val_loss: 8.2111 - val_accuracy: 0.4777\n",
            "Epoch 65/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.3966 - accuracy: 0.8954 - val_loss: 8.6828 - val_accuracy: 0.5422\n",
            "Epoch 66/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4181 - accuracy: 0.9015 - val_loss: 6.1105 - val_accuracy: 0.5557\n",
            "Epoch 67/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4107 - accuracy: 0.8901 - val_loss: 5.1984 - val_accuracy: 0.4968\n",
            "Epoch 68/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.5381 - accuracy: 0.8746 - val_loss: 6.5675 - val_accuracy: 0.5257\n",
            "Epoch 69/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4028 - accuracy: 0.8913 - val_loss: 4.7914 - val_accuracy: 0.5790\n",
            "Epoch 70/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.4395 - accuracy: 0.8690 - val_loss: 6.2686 - val_accuracy: 0.5781\n",
            "Epoch 71/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4274 - accuracy: 0.8752 - val_loss: 7.1469 - val_accuracy: 0.4914\n",
            "Epoch 72/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4136 - accuracy: 0.8817 - val_loss: 8.1061 - val_accuracy: 0.5197\n",
            "Epoch 73/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4254 - accuracy: 0.8847 - val_loss: 8.3683 - val_accuracy: 0.5692\n",
            "Epoch 74/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4087 - accuracy: 0.8845 - val_loss: 8.9877 - val_accuracy: 0.4955\n",
            "Epoch 75/500\n",
            "124/124 [==============================] - 6s 46ms/step - loss: 0.4036 - accuracy: 0.8858 - val_loss: 9.5894 - val_accuracy: 0.4828\n",
            "Epoch 76/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.8835 - accuracy: 0.8844 - val_loss: 8.8862 - val_accuracy: 0.5276\n",
            "Epoch 77/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4459 - accuracy: 0.8701 - val_loss: 9.3076 - val_accuracy: 0.4911\n",
            "Epoch 78/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4469 - accuracy: 0.8772 - val_loss: 9.2521 - val_accuracy: 0.5518\n",
            "Epoch 79/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4463 - accuracy: 0.8791 - val_loss: 8.3980 - val_accuracy: 0.4913\n",
            "Epoch 80/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4382 - accuracy: 0.8801 - val_loss: 8.6162 - val_accuracy: 0.4711\n",
            "Epoch 81/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4429 - accuracy: 0.8800 - val_loss: 9.3995 - val_accuracy: 0.4651\n",
            "Epoch 82/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4489 - accuracy: 0.8801 - val_loss: 9.2701 - val_accuracy: 0.4722\n",
            "Epoch 83/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4362 - accuracy: 0.8837 - val_loss: 9.3297 - val_accuracy: 0.4598\n",
            "Epoch 84/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4329 - accuracy: 0.8837 - val_loss: 9.1902 - val_accuracy: 0.4856\n",
            "Epoch 85/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4357 - accuracy: 0.8844 - val_loss: 8.8149 - val_accuracy: 0.4679\n",
            "Epoch 86/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4322 - accuracy: 0.8863 - val_loss: 9.3887 - val_accuracy: 0.4617\n",
            "Epoch 87/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4280 - accuracy: 0.8958 - val_loss: 7.8178 - val_accuracy: 0.4570\n",
            "Epoch 88/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4177 - accuracy: 0.9027 - val_loss: 6.9822 - val_accuracy: 0.4819\n",
            "Epoch 89/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4219 - accuracy: 0.9051 - val_loss: 7.8064 - val_accuracy: 0.4883\n",
            "Epoch 90/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.4218 - accuracy: 0.9063 - val_loss: 6.2259 - val_accuracy: 0.4875\n",
            "Epoch 91/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.4440 - accuracy: 0.8788 - val_loss: 7.3286 - val_accuracy: 0.5559\n",
            "Epoch 92/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4484 - accuracy: 0.8830 - val_loss: 8.1336 - val_accuracy: 0.4587\n",
            "Epoch 93/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4522 - accuracy: 0.8818 - val_loss: 6.3405 - val_accuracy: 0.4766\n",
            "Epoch 94/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4311 - accuracy: 0.8846 - val_loss: 6.2717 - val_accuracy: 0.5572\n",
            "Epoch 95/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4345 - accuracy: 0.8851 - val_loss: 6.7955 - val_accuracy: 0.5790\n",
            "Epoch 96/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4398 - accuracy: 0.8857 - val_loss: 5.9035 - val_accuracy: 0.4754\n",
            "Epoch 97/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4239 - accuracy: 0.8892 - val_loss: 7.2116 - val_accuracy: 0.4904\n",
            "Epoch 98/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4179 - accuracy: 0.8993 - val_loss: 6.2732 - val_accuracy: 0.4919\n",
            "Epoch 99/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4704 - accuracy: 0.8821 - val_loss: 7.0635 - val_accuracy: 0.4462\n",
            "Epoch 100/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4943 - accuracy: 0.8741 - val_loss: 6.6210 - val_accuracy: 0.6129\n",
            "Epoch 101/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4758 - accuracy: 0.8632 - val_loss: 6.8998 - val_accuracy: 0.5070\n",
            "Epoch 102/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4540 - accuracy: 0.8716 - val_loss: 7.0051 - val_accuracy: 0.5975\n",
            "Epoch 103/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.6591 - accuracy: 0.8717 - val_loss: 9.0112 - val_accuracy: 0.5183\n",
            "Epoch 104/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4291 - accuracy: 0.8781 - val_loss: 11.0917 - val_accuracy: 0.5035\n",
            "Epoch 105/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4170 - accuracy: 0.8838 - val_loss: 10.9470 - val_accuracy: 0.5029\n",
            "Epoch 106/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4137 - accuracy: 0.8853 - val_loss: 10.1396 - val_accuracy: 0.5735\n",
            "Epoch 107/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4089 - accuracy: 0.8830 - val_loss: 10.7924 - val_accuracy: 0.5982\n",
            "Epoch 108/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4084 - accuracy: 0.8867 - val_loss: 10.7130 - val_accuracy: 0.4959\n",
            "Epoch 109/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4976 - accuracy: 0.8828 - val_loss: 10.8265 - val_accuracy: 0.4651\n",
            "Epoch 110/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4164 - accuracy: 0.8833 - val_loss: 13.9351 - val_accuracy: 0.4538\n",
            "Epoch 111/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.4131 - accuracy: 0.8854 - val_loss: 10.6122 - val_accuracy: 0.4850\n",
            "Epoch 112/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4172 - accuracy: 0.8821 - val_loss: 10.2835 - val_accuracy: 0.4616\n",
            "Epoch 113/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4199 - accuracy: 0.8816 - val_loss: 11.1186 - val_accuracy: 0.4581\n",
            "Epoch 114/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4072 - accuracy: 0.8880 - val_loss: 13.3499 - val_accuracy: 0.4597\n",
            "Epoch 115/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4068 - accuracy: 0.8878 - val_loss: 12.4771 - val_accuracy: 0.5527\n",
            "Epoch 116/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4100 - accuracy: 0.8899 - val_loss: 12.6689 - val_accuracy: 0.4495\n",
            "Epoch 117/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4027 - accuracy: 0.8910 - val_loss: 12.3327 - val_accuracy: 0.5115\n",
            "Epoch 118/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4337 - accuracy: 0.8862 - val_loss: 11.9212 - val_accuracy: 0.5474\n",
            "Epoch 119/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4061 - accuracy: 0.8886 - val_loss: 11.7949 - val_accuracy: 0.4721\n",
            "Epoch 120/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4001 - accuracy: 0.8895 - val_loss: 12.5157 - val_accuracy: 0.5882\n",
            "Epoch 121/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3973 - accuracy: 0.8894 - val_loss: 12.3904 - val_accuracy: 0.5888\n",
            "Epoch 122/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4081 - accuracy: 0.8915 - val_loss: 12.0812 - val_accuracy: 0.4835\n",
            "Epoch 123/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4037 - accuracy: 0.8908 - val_loss: 11.4579 - val_accuracy: 0.4711\n",
            "Epoch 124/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3979 - accuracy: 0.8897 - val_loss: 11.8955 - val_accuracy: 0.4766\n",
            "Epoch 125/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4091 - accuracy: 0.8927 - val_loss: 10.9440 - val_accuracy: 0.4870\n",
            "Epoch 126/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3984 - accuracy: 0.8936 - val_loss: 11.9840 - val_accuracy: 0.4708\n",
            "Epoch 127/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4009 - accuracy: 0.9017 - val_loss: 9.2038 - val_accuracy: 0.4961\n",
            "Epoch 128/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3885 - accuracy: 0.9087 - val_loss: 7.6357 - val_accuracy: 0.4922\n",
            "Epoch 129/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3906 - accuracy: 0.9130 - val_loss: 10.6746 - val_accuracy: 0.4716\n",
            "Epoch 130/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3851 - accuracy: 0.9121 - val_loss: 7.7527 - val_accuracy: 0.5175\n",
            "Epoch 131/500\n",
            "124/124 [==============================] - 7s 59ms/step - loss: 0.5130 - accuracy: 0.8835 - val_loss: 8.4310 - val_accuracy: 0.4455\n",
            "Epoch 132/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.5582 - accuracy: 0.8889 - val_loss: 8.8779 - val_accuracy: 0.5911\n",
            "Epoch 133/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4221 - accuracy: 0.8886 - val_loss: 9.7077 - val_accuracy: 0.5576\n",
            "Epoch 134/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4304 - accuracy: 0.8904 - val_loss: 9.9559 - val_accuracy: 0.5949\n",
            "Epoch 135/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4073 - accuracy: 0.8923 - val_loss: 9.6671 - val_accuracy: 0.4790\n",
            "Epoch 136/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4088 - accuracy: 0.8919 - val_loss: 9.7233 - val_accuracy: 0.4975\n",
            "Epoch 137/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4144 - accuracy: 0.8801 - val_loss: 9.4561 - val_accuracy: 0.4820\n",
            "Epoch 138/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4206 - accuracy: 0.8829 - val_loss: 12.5439 - val_accuracy: 0.5968\n",
            "Epoch 139/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4133 - accuracy: 0.8893 - val_loss: 15.6440 - val_accuracy: 0.5830\n",
            "Epoch 140/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3983 - accuracy: 0.8960 - val_loss: 13.8123 - val_accuracy: 0.4479\n",
            "Epoch 141/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.4529 - accuracy: 0.8843 - val_loss: 15.5972 - val_accuracy: 0.4667\n",
            "Epoch 142/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4076 - accuracy: 0.9004 - val_loss: 16.1980 - val_accuracy: 0.4933\n",
            "Epoch 143/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3988 - accuracy: 0.9039 - val_loss: 13.6234 - val_accuracy: 0.5036\n",
            "Epoch 144/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3910 - accuracy: 0.9071 - val_loss: 11.2427 - val_accuracy: 0.4345\n",
            "Epoch 145/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4621 - accuracy: 0.8805 - val_loss: 10.1333 - val_accuracy: 0.6037\n",
            "Epoch 146/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4159 - accuracy: 0.8944 - val_loss: 8.9985 - val_accuracy: 0.4757\n",
            "Epoch 147/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3921 - accuracy: 0.9000 - val_loss: 8.0583 - val_accuracy: 0.4902\n",
            "Epoch 148/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3883 - accuracy: 0.9060 - val_loss: 8.8300 - val_accuracy: 0.5172\n",
            "Epoch 149/500\n",
            "124/124 [==============================] - 6s 47ms/step - loss: 0.3825 - accuracy: 0.9096 - val_loss: 9.5022 - val_accuracy: 0.5469\n",
            "Epoch 150/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4227 - accuracy: 0.9016 - val_loss: 9.6937 - val_accuracy: 0.4644\n",
            "Epoch 151/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.3980 - accuracy: 0.8991 - val_loss: 9.7440 - val_accuracy: 0.5156\n",
            "Epoch 152/500\n",
            "124/124 [==============================] - 7s 56ms/step - loss: 0.3806 - accuracy: 0.9078 - val_loss: 7.6744 - val_accuracy: 0.5119\n",
            "Epoch 153/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4082 - accuracy: 0.9057 - val_loss: 9.6040 - val_accuracy: 0.6043\n",
            "Epoch 154/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3997 - accuracy: 0.8951 - val_loss: 9.8125 - val_accuracy: 0.4841\n",
            "Epoch 155/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3933 - accuracy: 0.9020 - val_loss: 10.3380 - val_accuracy: 0.4452\n",
            "Epoch 156/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4047 - accuracy: 0.9033 - val_loss: 11.3111 - val_accuracy: 0.5156\n",
            "Epoch 157/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3914 - accuracy: 0.9087 - val_loss: 10.0079 - val_accuracy: 0.5110\n",
            "Epoch 158/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3967 - accuracy: 0.9121 - val_loss: 8.3965 - val_accuracy: 0.5343\n",
            "Epoch 159/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3750 - accuracy: 0.9130 - val_loss: 8.2053 - val_accuracy: 0.5597\n",
            "Epoch 160/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3976 - accuracy: 0.9135 - val_loss: 8.6056 - val_accuracy: 0.4859\n",
            "Epoch 161/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.4069 - accuracy: 0.8942 - val_loss: 8.0323 - val_accuracy: 0.5295\n",
            "Epoch 162/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3905 - accuracy: 0.9050 - val_loss: 9.7710 - val_accuracy: 0.5817\n",
            "Epoch 163/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.5056 - accuracy: 0.8760 - val_loss: 14.1020 - val_accuracy: 0.5003\n",
            "Epoch 164/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4205 - accuracy: 0.8949 - val_loss: 14.5187 - val_accuracy: 0.4777\n",
            "Epoch 165/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.4133 - accuracy: 0.9020 - val_loss: 13.8508 - val_accuracy: 0.5121\n",
            "Epoch 166/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3966 - accuracy: 0.9080 - val_loss: 12.0819 - val_accuracy: 0.5233\n",
            "Epoch 167/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4152 - accuracy: 0.9117 - val_loss: 8.0081 - val_accuracy: 0.5643\n",
            "Epoch 168/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4466 - accuracy: 0.8885 - val_loss: 11.1501 - val_accuracy: 0.5403\n",
            "Epoch 169/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4030 - accuracy: 0.9029 - val_loss: 11.7537 - val_accuracy: 0.6084\n",
            "Epoch 170/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4400 - accuracy: 0.9049 - val_loss: 11.0600 - val_accuracy: 0.5658\n",
            "Epoch 171/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.4251 - accuracy: 0.8911 - val_loss: 10.4364 - val_accuracy: 0.5110\n",
            "Epoch 172/500\n",
            "124/124 [==============================] - 7s 57ms/step - loss: 0.4173 - accuracy: 0.8874 - val_loss: 10.3817 - val_accuracy: 0.5069\n",
            "Epoch 173/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4017 - accuracy: 0.8971 - val_loss: 12.2630 - val_accuracy: 0.5401\n",
            "Epoch 174/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3945 - accuracy: 0.9019 - val_loss: 11.6159 - val_accuracy: 0.5468\n",
            "Epoch 175/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3744 - accuracy: 0.9089 - val_loss: 10.3111 - val_accuracy: 0.6067\n",
            "Epoch 176/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3848 - accuracy: 0.9099 - val_loss: 10.1027 - val_accuracy: 0.5181\n",
            "Epoch 177/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.8660 - accuracy: 0.8885 - val_loss: 12.5333 - val_accuracy: 0.4863\n",
            "Epoch 178/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4050 - accuracy: 0.9048 - val_loss: 11.1846 - val_accuracy: 0.5268\n",
            "Epoch 179/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3981 - accuracy: 0.9055 - val_loss: 10.8111 - val_accuracy: 0.4793\n",
            "[(0.6258227825164795, 119, 'learning rate :0.1', 'std :1'), (0.6905485391616821, 110, 'learning rate :0.1', 'std :0.1'), (0.6213502287864685, 28, 'learning rate :0.1', 'std :0.01')]\n",
            "Epoch 1/500\n",
            "124/124 [==============================] - 7s 51ms/step - loss: 1.1646 - accuracy: 0.8564 - val_loss: 5.7820 - val_accuracy: 0.5505\n",
            "Epoch 2/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.5874 - accuracy: 0.9074 - val_loss: 3.6374 - val_accuracy: 0.5372\n",
            "Epoch 3/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4101 - accuracy: 0.9080 - val_loss: 2.7534 - val_accuracy: 0.5743\n",
            "Epoch 4/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.4118 - accuracy: 0.9148 - val_loss: 3.8622 - val_accuracy: 0.5764\n",
            "Epoch 5/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3807 - accuracy: 0.9210 - val_loss: 4.2976 - val_accuracy: 0.5797\n",
            "Epoch 6/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2731 - accuracy: 0.9198 - val_loss: 4.9445 - val_accuracy: 0.6034\n",
            "Epoch 7/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2477 - accuracy: 0.9305 - val_loss: 5.4000 - val_accuracy: 0.6095\n",
            "Epoch 8/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.2859 - accuracy: 0.9226 - val_loss: 5.7098 - val_accuracy: 0.5913\n",
            "Epoch 9/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2350 - accuracy: 0.9293 - val_loss: 6.2002 - val_accuracy: 0.5679\n",
            "Epoch 10/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2464 - accuracy: 0.9333 - val_loss: 6.6429 - val_accuracy: 0.5932\n",
            "Epoch 11/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2304 - accuracy: 0.9335 - val_loss: 6.3557 - val_accuracy: 0.5852\n",
            "Epoch 12/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2207 - accuracy: 0.9344 - val_loss: 7.0498 - val_accuracy: 0.5819\n",
            "Epoch 13/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2216 - accuracy: 0.9372 - val_loss: 6.2491 - val_accuracy: 0.6129\n",
            "Epoch 14/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2276 - accuracy: 0.9354 - val_loss: 7.3272 - val_accuracy: 0.5727\n",
            "Epoch 15/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2284 - accuracy: 0.9389 - val_loss: 7.6447 - val_accuracy: 0.5567\n",
            "Epoch 16/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2696 - accuracy: 0.9379 - val_loss: 9.3505 - val_accuracy: 0.5513\n",
            "Epoch 17/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.2503 - accuracy: 0.9382 - val_loss: 8.3134 - val_accuracy: 0.5986\n",
            "Epoch 18/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2377 - accuracy: 0.9377 - val_loss: 9.1762 - val_accuracy: 0.5823\n",
            "Epoch 19/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2365 - accuracy: 0.9322 - val_loss: 8.2854 - val_accuracy: 0.5848\n",
            "Epoch 20/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2426 - accuracy: 0.9316 - val_loss: 8.3822 - val_accuracy: 0.6227\n",
            "Epoch 21/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2484 - accuracy: 0.9319 - val_loss: 8.2102 - val_accuracy: 0.5842\n",
            "Epoch 22/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.4946 - accuracy: 0.9333 - val_loss: 8.7675 - val_accuracy: 0.5813\n",
            "Epoch 23/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2393 - accuracy: 0.9346 - val_loss: 9.5703 - val_accuracy: 0.5797\n",
            "Epoch 24/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2506 - accuracy: 0.9399 - val_loss: 9.2380 - val_accuracy: 0.5635\n",
            "Epoch 25/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2640 - accuracy: 0.9297 - val_loss: 9.8333 - val_accuracy: 0.5646\n",
            "Epoch 26/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2718 - accuracy: 0.9227 - val_loss: 7.4596 - val_accuracy: 0.6024\n",
            "Epoch 27/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2655 - accuracy: 0.9178 - val_loss: 7.8028 - val_accuracy: 0.5570\n",
            "Epoch 28/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.2723 - accuracy: 0.9229 - val_loss: 8.6830 - val_accuracy: 0.5532\n",
            "Epoch 29/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3794 - accuracy: 0.9123 - val_loss: 8.7710 - val_accuracy: 0.5650\n",
            "Epoch 30/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2957 - accuracy: 0.9218 - val_loss: 9.8866 - val_accuracy: 0.5674\n",
            "Epoch 31/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3041 - accuracy: 0.9165 - val_loss: 9.6762 - val_accuracy: 0.6096\n",
            "Epoch 32/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3199 - accuracy: 0.9176 - val_loss: 11.0812 - val_accuracy: 0.5959\n",
            "Epoch 33/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2432 - accuracy: 0.9273 - val_loss: 16.2112 - val_accuracy: 0.5508\n",
            "Epoch 34/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2623 - accuracy: 0.9368 - val_loss: 12.7623 - val_accuracy: 0.5507\n",
            "Epoch 35/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2719 - accuracy: 0.9309 - val_loss: 16.9888 - val_accuracy: 0.5090\n",
            "Epoch 36/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2747 - accuracy: 0.9240 - val_loss: 12.6813 - val_accuracy: 0.6281\n",
            "Epoch 37/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.4723 - accuracy: 0.9169 - val_loss: 11.8021 - val_accuracy: 0.6347\n",
            "Epoch 38/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3146 - accuracy: 0.9134 - val_loss: 12.6862 - val_accuracy: 0.6117\n",
            "Epoch 39/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2688 - accuracy: 0.9152 - val_loss: 13.5253 - val_accuracy: 0.6457\n",
            "Epoch 40/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3530 - accuracy: 0.9161 - val_loss: 15.2296 - val_accuracy: 0.5468\n",
            "Epoch 41/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2792 - accuracy: 0.9258 - val_loss: 15.0726 - val_accuracy: 0.5944\n",
            "Epoch 42/500\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.3228 - accuracy: 0.9210 - val_loss: 13.7831 - val_accuracy: 0.6508\n",
            "Epoch 43/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2670 - accuracy: 0.9192 - val_loss: 12.3110 - val_accuracy: 0.6141\n",
            "Epoch 44/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2651 - accuracy: 0.9238 - val_loss: 13.3779 - val_accuracy: 0.6217\n",
            "Epoch 45/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2528 - accuracy: 0.9268 - val_loss: 13.4193 - val_accuracy: 0.6335\n",
            "Epoch 46/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2836 - accuracy: 0.9270 - val_loss: 15.3957 - val_accuracy: 0.6416\n",
            "Epoch 47/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.3126 - accuracy: 0.9230 - val_loss: 16.0033 - val_accuracy: 0.6152\n",
            "Epoch 48/500\n",
            "124/124 [==============================] - 7s 60ms/step - loss: 0.2596 - accuracy: 0.9279 - val_loss: 16.8903 - val_accuracy: 0.6279\n",
            "Epoch 49/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2452 - accuracy: 0.9410 - val_loss: 15.7132 - val_accuracy: 0.6074\n",
            "Epoch 50/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2551 - accuracy: 0.9263 - val_loss: 17.4994 - val_accuracy: 0.6012\n",
            "Epoch 51/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2650 - accuracy: 0.9187 - val_loss: 13.7603 - val_accuracy: 0.4738\n",
            "Epoch 52/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2786 - accuracy: 0.9195 - val_loss: 13.7459 - val_accuracy: 0.5608\n",
            "Epoch 53/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2834 - accuracy: 0.9227 - val_loss: 15.8708 - val_accuracy: 0.5349\n",
            "Epoch 54/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2602 - accuracy: 0.9254 - val_loss: 16.8848 - val_accuracy: 0.5047\n",
            "Epoch 55/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2628 - accuracy: 0.9296 - val_loss: 17.8321 - val_accuracy: 0.5905\n",
            "Epoch 56/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2414 - accuracy: 0.9434 - val_loss: 16.6850 - val_accuracy: 0.6256\n",
            "Epoch 57/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2538 - accuracy: 0.9346 - val_loss: 13.2820 - val_accuracy: 0.5586\n",
            "Epoch 58/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3023 - accuracy: 0.9189 - val_loss: 15.7400 - val_accuracy: 0.6123\n",
            "Epoch 59/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2590 - accuracy: 0.9282 - val_loss: 16.8715 - val_accuracy: 0.6172\n",
            "Epoch 60/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2424 - accuracy: 0.9287 - val_loss: 17.9797 - val_accuracy: 0.5272\n",
            "Epoch 61/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3190 - accuracy: 0.9269 - val_loss: 18.5680 - val_accuracy: 0.6190\n",
            "Epoch 62/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.3483 - accuracy: 0.9257 - val_loss: 16.9976 - val_accuracy: 0.6394\n",
            "Epoch 63/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3055 - accuracy: 0.9266 - val_loss: 15.4851 - val_accuracy: 0.6564\n",
            "Epoch 64/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2752 - accuracy: 0.9294 - val_loss: 13.6226 - val_accuracy: 0.6527\n",
            "Epoch 65/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3006 - accuracy: 0.9260 - val_loss: 14.9037 - val_accuracy: 0.6477\n",
            "Epoch 66/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2823 - accuracy: 0.9286 - val_loss: 16.9982 - val_accuracy: 0.6305\n",
            "Epoch 67/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.2406 - accuracy: 0.9309 - val_loss: 18.5807 - val_accuracy: 0.6388\n",
            "Epoch 68/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2631 - accuracy: 0.9329 - val_loss: 19.6527 - val_accuracy: 0.6367\n",
            "Epoch 69/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2700 - accuracy: 0.9389 - val_loss: 18.3748 - val_accuracy: 0.6423\n",
            "Epoch 70/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2684 - accuracy: 0.9444 - val_loss: 18.3657 - val_accuracy: 0.6518\n",
            "Epoch 71/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2689 - accuracy: 0.9480 - val_loss: 11.9104 - val_accuracy: 0.6533\n",
            "Epoch 72/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2862 - accuracy: 0.9401 - val_loss: 11.7942 - val_accuracy: 0.6181\n",
            "Epoch 73/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2555 - accuracy: 0.9434 - val_loss: 7.9458 - val_accuracy: 0.6498\n",
            "Epoch 74/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2653 - accuracy: 0.9367 - val_loss: 11.5075 - val_accuracy: 0.5695\n",
            "Epoch 75/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2662 - accuracy: 0.9259 - val_loss: 11.3194 - val_accuracy: 0.6200\n",
            "Epoch 76/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2657 - accuracy: 0.9243 - val_loss: 8.9141 - val_accuracy: 0.6501\n",
            "Epoch 77/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2415 - accuracy: 0.9231 - val_loss: 11.2831 - val_accuracy: 0.6165\n",
            "Epoch 78/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2027 - accuracy: 0.9321 - val_loss: 11.9566 - val_accuracy: 0.6080\n",
            "Epoch 79/500\n",
            "124/124 [==============================] - 6s 49ms/step - loss: 0.2436 - accuracy: 0.9332 - val_loss: 11.4977 - val_accuracy: 0.6147\n",
            "Epoch 80/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2249 - accuracy: 0.9323 - val_loss: 13.2548 - val_accuracy: 0.6254\n",
            "Epoch 81/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3022 - accuracy: 0.9290 - val_loss: 10.0109 - val_accuracy: 0.5022\n",
            "Epoch 82/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3104 - accuracy: 0.9251 - val_loss: 10.6855 - val_accuracy: 0.5841\n",
            "Epoch 83/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2765 - accuracy: 0.9270 - val_loss: 8.7280 - val_accuracy: 0.6209\n",
            "Epoch 84/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2581 - accuracy: 0.9337 - val_loss: 11.1561 - val_accuracy: 0.6276\n",
            "Epoch 85/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2449 - accuracy: 0.9437 - val_loss: 10.0619 - val_accuracy: 0.6070\n",
            "Epoch 86/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2328 - accuracy: 0.9435 - val_loss: 9.9882 - val_accuracy: 0.6192\n",
            "Epoch 87/500\n",
            "124/124 [==============================] - 8s 62ms/step - loss: 0.2335 - accuracy: 0.9477 - val_loss: 10.3390 - val_accuracy: 0.5884\n",
            "Epoch 88/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2289 - accuracy: 0.9476 - val_loss: 7.0473 - val_accuracy: 0.6310\n",
            "Epoch 89/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2022 - accuracy: 0.9491 - val_loss: 9.0023 - val_accuracy: 0.6200\n",
            "Epoch 90/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2312 - accuracy: 0.9491 - val_loss: 8.9591 - val_accuracy: 0.5532\n",
            "Epoch 91/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2082 - accuracy: 0.9491 - val_loss: 10.1586 - val_accuracy: 0.6094\n",
            "Epoch 92/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2160 - accuracy: 0.9509 - val_loss: 8.2499 - val_accuracy: 0.6463\n",
            "Epoch 93/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2139 - accuracy: 0.9487 - val_loss: 10.4715 - val_accuracy: 0.6350\n",
            "Epoch 94/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.3785 - accuracy: 0.9227 - val_loss: 11.7942 - val_accuracy: 0.6419\n",
            "Epoch 95/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3124 - accuracy: 0.9156 - val_loss: 13.8008 - val_accuracy: 0.6426\n",
            "Epoch 96/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2670 - accuracy: 0.9247 - val_loss: 15.2888 - val_accuracy: 0.6491\n",
            "Epoch 97/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2452 - accuracy: 0.9306 - val_loss: 15.4487 - val_accuracy: 0.6542\n",
            "Epoch 98/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2449 - accuracy: 0.9329 - val_loss: 16.2083 - val_accuracy: 0.6347\n",
            "Epoch 99/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2691 - accuracy: 0.9334 - val_loss: 16.7676 - val_accuracy: 0.5915\n",
            "Epoch 100/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2660 - accuracy: 0.9375 - val_loss: 16.1768 - val_accuracy: 0.5866\n",
            "Epoch 101/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2686 - accuracy: 0.9404 - val_loss: 15.0231 - val_accuracy: 0.5767\n",
            "Epoch 102/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2316 - accuracy: 0.9429 - val_loss: 14.6146 - val_accuracy: 0.5808\n",
            "Epoch 103/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2676 - accuracy: 0.9451 - val_loss: 14.5398 - val_accuracy: 0.5714\n",
            "Epoch 104/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2724 - accuracy: 0.9427 - val_loss: 13.7262 - val_accuracy: 0.5978\n",
            "Epoch 105/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3204 - accuracy: 0.9441 - val_loss: 13.1030 - val_accuracy: 0.6240\n",
            "Epoch 106/500\n",
            "124/124 [==============================] - 7s 61ms/step - loss: 0.3186 - accuracy: 0.9316 - val_loss: 14.7002 - val_accuracy: 0.6205\n",
            "Epoch 107/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2358 - accuracy: 0.9400 - val_loss: 15.5569 - val_accuracy: 0.6372\n",
            "Epoch 108/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2524 - accuracy: 0.9419 - val_loss: 15.5634 - val_accuracy: 0.6008\n",
            "Epoch 109/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2622 - accuracy: 0.9427 - val_loss: 13.8499 - val_accuracy: 0.6349\n",
            "Epoch 110/500\n",
            "124/124 [==============================] - 7s 52ms/step - loss: 0.2835 - accuracy: 0.9451 - val_loss: 16.3591 - val_accuracy: 0.6257\n",
            "Epoch 111/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2538 - accuracy: 0.9456 - val_loss: 15.5482 - val_accuracy: 0.6415\n",
            "Epoch 112/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3062 - accuracy: 0.9301 - val_loss: 17.4270 - val_accuracy: 0.6540\n",
            "Epoch 113/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2675 - accuracy: 0.9465 - val_loss: 16.2528 - val_accuracy: 0.6416\n",
            "Epoch 114/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2374 - accuracy: 0.9428 - val_loss: 19.0873 - val_accuracy: 0.6149\n",
            "Epoch 115/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2324 - accuracy: 0.9505 - val_loss: 16.9104 - val_accuracy: 0.6358\n",
            "Epoch 116/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2427 - accuracy: 0.9523 - val_loss: 17.7438 - val_accuracy: 0.6423\n",
            "Epoch 117/500\n",
            "124/124 [==============================] - 7s 52ms/step - loss: 0.2157 - accuracy: 0.9459 - val_loss: 17.5509 - val_accuracy: 0.6447\n",
            "Epoch 118/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3292 - accuracy: 0.9320 - val_loss: 13.7380 - val_accuracy: 0.6292\n",
            "Epoch 119/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2753 - accuracy: 0.9365 - val_loss: 15.4868 - val_accuracy: 0.6451\n",
            "Epoch 120/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2673 - accuracy: 0.9477 - val_loss: 15.3157 - val_accuracy: 0.6516\n",
            "Epoch 121/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2309 - accuracy: 0.9517 - val_loss: 15.3536 - val_accuracy: 0.6415\n",
            "Epoch 122/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2412 - accuracy: 0.9515 - val_loss: 17.8525 - val_accuracy: 0.6582\n",
            "Epoch 123/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2303 - accuracy: 0.9527 - val_loss: 14.5813 - val_accuracy: 0.6397\n",
            "Epoch 124/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2399 - accuracy: 0.9517 - val_loss: 17.4580 - val_accuracy: 0.6451\n",
            "Epoch 125/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.5010 - accuracy: 0.9313 - val_loss: 12.3379 - val_accuracy: 0.6170\n",
            "Epoch 126/500\n",
            "124/124 [==============================] - 8s 61ms/step - loss: 0.2685 - accuracy: 0.9304 - val_loss: 17.5456 - val_accuracy: 0.6537\n",
            "Epoch 127/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3092 - accuracy: 0.9375 - val_loss: 18.4400 - val_accuracy: 0.6516\n",
            "Epoch 128/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2961 - accuracy: 0.9428 - val_loss: 17.3884 - val_accuracy: 0.6729\n",
            "Epoch 129/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.3167 - accuracy: 0.9460 - val_loss: 17.1005 - val_accuracy: 0.6366\n",
            "Epoch 130/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2414 - accuracy: 0.9510 - val_loss: 16.2456 - val_accuracy: 0.6422\n",
            "Epoch 131/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2608 - accuracy: 0.9513 - val_loss: 16.7667 - val_accuracy: 0.6484\n",
            "Epoch 132/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2342 - accuracy: 0.9361 - val_loss: 17.6410 - val_accuracy: 0.6146\n",
            "Epoch 133/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2904 - accuracy: 0.9500 - val_loss: 17.2072 - val_accuracy: 0.6722\n",
            "Epoch 134/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2816 - accuracy: 0.9508 - val_loss: 16.8858 - val_accuracy: 0.6729\n",
            "Epoch 135/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2414 - accuracy: 0.9526 - val_loss: 16.5225 - val_accuracy: 0.6668\n",
            "Epoch 136/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2517 - accuracy: 0.9521 - val_loss: 15.0995 - val_accuracy: 0.6407\n",
            "Epoch 137/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.2710 - accuracy: 0.9508 - val_loss: 13.6017 - val_accuracy: 0.6528\n",
            "Epoch 138/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.3207 - accuracy: 0.9422 - val_loss: 14.2045 - val_accuracy: 0.6489\n",
            "Epoch 139/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2918 - accuracy: 0.9280 - val_loss: 16.4896 - val_accuracy: 0.6367\n",
            "Epoch 140/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3410 - accuracy: 0.9273 - val_loss: 16.6216 - val_accuracy: 0.6646\n",
            "Epoch 141/500\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.3244 - accuracy: 0.9267 - val_loss: 16.1562 - val_accuracy: 0.6232\n",
            "Epoch 142/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2888 - accuracy: 0.9282 - val_loss: 15.7573 - val_accuracy: 0.6487\n",
            "Epoch 143/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2784 - accuracy: 0.9299 - val_loss: 17.6502 - val_accuracy: 0.6327\n",
            "Epoch 144/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2694 - accuracy: 0.9357 - val_loss: 19.3196 - val_accuracy: 0.6482\n",
            "Epoch 145/500\n",
            "124/124 [==============================] - 8s 64ms/step - loss: 0.2838 - accuracy: 0.9342 - val_loss: 18.8382 - val_accuracy: 0.6406\n",
            "Epoch 146/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2525 - accuracy: 0.9465 - val_loss: 18.5600 - val_accuracy: 0.6381\n",
            "Epoch 147/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2494 - accuracy: 0.9523 - val_loss: 18.3460 - val_accuracy: 0.6105\n",
            "Epoch 148/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2358 - accuracy: 0.9533 - val_loss: 16.3359 - val_accuracy: 0.6328\n",
            "Epoch 149/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2557 - accuracy: 0.9493 - val_loss: 17.6339 - val_accuracy: 0.6464\n",
            "Epoch 150/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2758 - accuracy: 0.9444 - val_loss: 17.6457 - val_accuracy: 0.6414\n",
            "Epoch 151/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2879 - accuracy: 0.9292 - val_loss: 18.1623 - val_accuracy: 0.6120\n",
            "Epoch 152/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2859 - accuracy: 0.9285 - val_loss: 19.4353 - val_accuracy: 0.5161\n",
            "Epoch 153/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2672 - accuracy: 0.9314 - val_loss: 20.1246 - val_accuracy: 0.6525\n",
            "Epoch 154/500\n",
            "124/124 [==============================] - 7s 52ms/step - loss: 0.2482 - accuracy: 0.9409 - val_loss: 20.8131 - val_accuracy: 0.6733\n",
            "Epoch 155/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2721 - accuracy: 0.9432 - val_loss: 22.1470 - val_accuracy: 0.6652\n",
            "Epoch 156/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2680 - accuracy: 0.9511 - val_loss: 22.7561 - val_accuracy: 0.6551\n",
            "Epoch 157/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2486 - accuracy: 0.9511 - val_loss: 20.4057 - val_accuracy: 0.6720\n",
            "Epoch 158/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2468 - accuracy: 0.9529 - val_loss: 21.2408 - val_accuracy: 0.6668\n",
            "Epoch 159/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2515 - accuracy: 0.9533 - val_loss: 21.8579 - val_accuracy: 0.6553\n",
            "Epoch 160/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2504 - accuracy: 0.9538 - val_loss: 23.2238 - val_accuracy: 0.6439\n",
            "Epoch 161/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2550 - accuracy: 0.9535 - val_loss: 22.9840 - val_accuracy: 0.5780\n",
            "Epoch 162/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2511 - accuracy: 0.9554 - val_loss: 24.2005 - val_accuracy: 0.6418\n",
            "Epoch 163/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.3105 - accuracy: 0.9403 - val_loss: 24.2126 - val_accuracy: 0.5612\n",
            "Epoch 164/500\n",
            "124/124 [==============================] - 8s 63ms/step - loss: 0.2317 - accuracy: 0.9546 - val_loss: 24.0841 - val_accuracy: 0.5687\n",
            "Epoch 165/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2331 - accuracy: 0.9520 - val_loss: 22.5612 - val_accuracy: 0.6019\n",
            "Epoch 166/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2927 - accuracy: 0.9285 - val_loss: 22.2123 - val_accuracy: 0.5948\n",
            "Epoch 167/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2725 - accuracy: 0.9306 - val_loss: 21.6473 - val_accuracy: 0.6310\n",
            "Epoch 168/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2655 - accuracy: 0.9318 - val_loss: 23.7829 - val_accuracy: 0.5263\n",
            "Epoch 169/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2610 - accuracy: 0.9281 - val_loss: 10.5547 - val_accuracy: 0.5713\n",
            "Epoch 170/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.2928 - accuracy: 0.9242 - val_loss: 10.4982 - val_accuracy: 0.6125\n",
            "Epoch 171/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2941 - accuracy: 0.9253 - val_loss: 10.5159 - val_accuracy: 0.5926\n",
            "Epoch 172/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2978 - accuracy: 0.9218 - val_loss: 12.2775 - val_accuracy: 0.5652\n",
            "Epoch 173/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2668 - accuracy: 0.9261 - val_loss: 15.8908 - val_accuracy: 0.5471\n",
            "Epoch 174/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.2999 - accuracy: 0.9223 - val_loss: 13.5782 - val_accuracy: 0.5513\n",
            "Epoch 175/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2626 - accuracy: 0.9376 - val_loss: 11.3275 - val_accuracy: 0.5670\n",
            "Epoch 176/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2908 - accuracy: 0.9356 - val_loss: 12.4574 - val_accuracy: 0.5870\n",
            "Epoch 177/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.3136 - accuracy: 0.9271 - val_loss: 13.2953 - val_accuracy: 0.5752\n",
            "Epoch 178/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2630 - accuracy: 0.9391 - val_loss: 14.0247 - val_accuracy: 0.5559\n",
            "Epoch 179/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.3442 - accuracy: 0.9392 - val_loss: 13.3498 - val_accuracy: 0.4544\n",
            "Epoch 180/500\n",
            "124/124 [==============================] - 7s 52ms/step - loss: 0.3243 - accuracy: 0.9381 - val_loss: 10.5388 - val_accuracy: 0.5594\n",
            "Epoch 181/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 1.0373 - accuracy: 0.9363 - val_loss: 11.1709 - val_accuracy: 0.6056\n",
            "Epoch 182/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2763 - accuracy: 0.9468 - val_loss: 10.5360 - val_accuracy: 0.5349\n",
            "Epoch 183/500\n",
            "124/124 [==============================] - 8s 63ms/step - loss: 0.3290 - accuracy: 0.9456 - val_loss: 9.6466 - val_accuracy: 0.6354\n",
            "Epoch 184/500\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.2985 - accuracy: 0.9459 - val_loss: 9.1407 - val_accuracy: 0.5828\n",
            "Epoch 185/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.3033 - accuracy: 0.9448 - val_loss: 8.9305 - val_accuracy: 0.5601\n",
            "Epoch 186/500\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.2944 - accuracy: 0.9496 - val_loss: 7.9103 - val_accuracy: 0.6315\n",
            "Epoch 187/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.2785 - accuracy: 0.9456 - val_loss: 7.6825 - val_accuracy: 0.6365\n",
            "Epoch 188/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.3236 - accuracy: 0.9425 - val_loss: 13.0746 - val_accuracy: 0.5611\n",
            "Epoch 189/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.2737 - accuracy: 0.9528 - val_loss: 11.8146 - val_accuracy: 0.5749\n",
            "Epoch 190/500\n",
            "124/124 [==============================] - 7s 54ms/step - loss: 0.2377 - accuracy: 0.9535 - val_loss: 11.6993 - val_accuracy: 0.5662\n",
            "Epoch 191/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.2561 - accuracy: 0.9368 - val_loss: 11.6837 - val_accuracy: 0.6024\n",
            "Epoch 192/500\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.3417 - accuracy: 0.9101 - val_loss: 10.9214 - val_accuracy: 0.5581\n",
            "Epoch 193/500\n",
            " 97/124 [======================>.......] - ETA: 1s - loss: 0.3017 - accuracy: 0.9013"
          ]
        }
      ],
      "source": [
        "# model,history = MULTI_CNN1D(trainInput,trainOutput,test21Input,test21Output,0.1,0.1)\n",
        "trainInput.shape\n",
        "max_accuracy=[]\n",
        "for i in range(1,4):\n",
        "  for j in range(4):\n",
        "    lr = 10 ** (-i)\n",
        "    stddev =10 ** (-j)\n",
        "    model,history = MULTI_CNN1D(trainInput,trainOutput,test21Input,test21Output,lr,stddev)\n",
        "    max_accuracy.append((max(history.history[\"val_accuracy\"]),history.history[\"val_accuracy\"].index(max(history.history[\"val_accuracy\"])),\"learning rate :\"+str(lr),\"std :\"+str(stddev)))\n",
        "    print (max_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYmJ3i1R58L",
        "outputId": "7198087c-f81b-4123-aad2-d4e31b4aec57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as re_lu_54_layer_call_fn, re_lu_54_layer_call_and_return_conditional_losses, re_lu_55_layer_call_fn, re_lu_55_layer_call_and_return_conditional_losses, re_lu_56_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/test/cnn_1d_new/multi/1/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/test/cnn_1d_new/multi/1/assets\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/test/cnn_1d_new/multi/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5o9TvAAR547"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(trainOutput),y=trainOutput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL9hMgV9R52L"
      },
      "outputs": [],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wukocgCsR5zQ"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/test/cnn_1d_new/binary/93_1_4_1e-3_39')\n",
        "# # Evaluate the model\n",
        "loss, acc = model.evaluate(trainInput, trainOutput, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
        "loss, acc = model.evaluate(testInput, testOutput, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
        "loss, acc = model.evaluate(test21Input, test21Output, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8KbOJIIR5ws"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHRIOSXJR5tF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qycaR6BaR5rJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkLhdRq_R5i0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_mscIuCR5UR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ox_nfq-QYJo"
      },
      "outputs": [],
      "source": [
        "input=Input(shape=(122))\n",
        "reshape=layers.Reshape((1,122))(input)\n",
        "layer1=layers.Conv1D(filters=32,activation=\"ReLU\",name=\"Conv1d_1\",kernel_size=3,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(reshape)\n",
        "layer1=layers.MaxPooling1D(pool_size=2,strides=1,name=\"MaxPooling_1\",padding=\"same\")(layer1)\n",
        "layer1=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_1\")(layer1)\n",
        "flatten1=layers.Flatten()(layer1)\n",
        "\n",
        "layer2=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_2\",kernel_size=4,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer1)\n",
        "layer2=layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling_2\",padding=\"same\")(layer2)\n",
        "layer2=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_2\")(layer2)\n",
        "flatten2=layers.Flatten()(layer2)\n",
        "\n",
        "layer3=layers.Conv1D(filters=124,activation=\"ReLU\",name=\"Conv1d_3\",kernel_size=8,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer2)\n",
        "layer3=layers.MaxPool1D(pool_size=8,strides=1,name=\"MaxPooling_3\",padding=\"same\")(layer3)\n",
        "layer3=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_3\")(layer3)\n",
        "flatten3=layers.Flatten()(layer3)\n",
        "\n",
        "Dense1=Dense(256,activation=\"relu\",name=\"Dense_Layer_1\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(flatten3)\n",
        "dropout=layers.Dropout(rate=0.1,name=\"Dropoutlayer_4\")(Dense1)\n",
        "Dense2=Dense(5,activation=\"softmax\",name=\"Dense_Layer_2\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(dropout)\n",
        "x=layers.Concatenate()([Dense2,flatten3,flatten2,flatten1])\n",
        "output=Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(x)\n",
        "model=keras.Model(inputs=input,outputs=output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUPrq_9NQYJp",
        "outputId": "7dc88761-480c-4fe7-9ee3-7fc3e0081676"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "LSTM.__init__() missing 1 required positional argument: 'units'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mf:\\try2.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=1'>2</a>\u001b[0m left \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=2'>3</a>\u001b[0m left\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39;49mLSTM(output_dim\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muniform\u001b[39;49m\u001b[39m'\u001b[39;49m, inner_init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muniform\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=3'>4</a>\u001b[0m forget_bias_init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mone\u001b[39;49m\u001b[39m'\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtanh\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=4'>5</a>\u001b[0m inner_activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=5'>6</a>\u001b[0m right \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=6'>7</a>\u001b[0m right\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mLSTM(output_dim\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, inner_init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=7'>8</a>\u001b[0m forget_bias_init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mone\u001b[39m\u001b[39m'\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/try2.ipynb#ch0000030?line=8'>9</a>\u001b[0m inner_activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m), go_backwards\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
            "\u001b[1;31mTypeError\u001b[0m: LSTM.__init__() missing 1 required positional argument: 'units'"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "left = Sequential()\n",
        "left.add(layers.LSTM(output_dim=256, init='uniform', inner_init='uniform',\n",
        "forget_bias_init='one', return_sequences=True, activation='tanh',\n",
        "inner_activation='sigmoid', input_shape=(32, 32)))\n",
        "right = Sequential()\n",
        "right.add(layers.LSTM(output_dim=256, init='uniform', inner_init='uniform',\n",
        "forget_bias_init='one', return_sequences=True, activation='tanh',\n",
        "inner_activation='sigmoid', input_shape=(32, 32), go_backwards=True))\n",
        "\n",
        "model.add(layers.Merge([left, right],'sum'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Jh58z0QYJr"
      },
      "outputs": [],
      "source": [
        "def MULTI_CNN1D(input_train,output_train,testinput,testoutput,classweights):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    input=Input(shape=(122))\n",
        "    reshape=layers.Reshape((1,122))(input)\n",
        "    layer1=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_1\",kernel_size=2,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(reshape)\n",
        "    layer1=layers.MaxPooling1D(pool_size=2,strides=1,name=\"MaxPooling_1\",padding=\"same\")(layer1)\n",
        "    layer1=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_1\")(layer1)\n",
        "    flatten1=layers.Flatten()(layer1)\n",
        "\n",
        "    layer2=layers.Conv1D(filters=62,activation=\"ReLU\",name=\"Conv1d_2\",kernel_size=4,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer1)\n",
        "    layer2=layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling_2\",padding=\"same\")(layer2)\n",
        "    layer2=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_2\")(layer2)\n",
        "    flatten2=layers.Flatten()(layer2)\n",
        "\n",
        "    layer3=layers.Conv1D(filters=124,activation=\"ReLU\",name=\"Conv1d_3\",kernel_size=8,strides=1,padding=\"same\",kernel_initializer=\"glorot_uniform\", bias_initializer=initializers.Zeros())(layer2)\n",
        "    layer3=layers.MaxPool1D(pool_size=8,strides=1,name=\"MaxPooling_3\",padding=\"same\")(layer3)\n",
        "    layer3=layers.SpatialDropout1D(rate=0.1,name=\"Dropoutlayer_3\")(layer3)\n",
        "    flatten3=layers.Flatten()(layer3)\n",
        "    \n",
        "    Dense1=Dense(256,activation=\"relu\",name=\"Dense_Layer_1\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(flatten3)\n",
        "    dropout=layers.Dropout(rate=0.1,name=\"Dropoutlayer_4\")(Dense1)\n",
        "    Dense2=Dense(5,activation=\"softmax\",name=\"Dense_Layer_2\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(dropout)\n",
        "    x=layers.Concatenate()([Dense2,flatten3,flatten2,flatten1])\n",
        "    output=Dense(5,activation=\"softmax\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros())(x)\n",
        "    model=keras.Model(inputs=input,outputs=output)\n",
        "\n",
        "    model._name=\"Multi-Stage_features_CNN1D\"\n",
        "    decaying_learning_rate=tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.05 if epoch<74 else 0.00005)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=0.05),metrics=['accuracy'])\n",
        "    history=model.fit(input_train,output_train,epochs=75,batch_size=128,validation_data=(testinput,testoutput),class_weight=classweights,callbacks=[decaying_learning_rate])\n",
        "    return model,history\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWVTnPekQYJs"
      },
      "outputs": [],
      "source": [
        "def BI_CNN2D(input_train,output_train,testinput,testoutput,classweights):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    model=Sequential()\n",
        "    model.add(layers.Reshape((11, 11,1), input_shape=(None,122)))\n",
        "    model.add(layers.Conv2D(filters=20,activation=\"ReLU\",name=\"Conv2D_1\",kernel_size=(4,4),strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),name=\"MaxPooling_1\"))\n",
        "    model.add(layers.SpatialDropout2D(rate=0.1,name=\"Dropoutlayer_1\"))\n",
        "    model.add(layers.Conv2D(filters=40,activation=\"ReLU\",name=\"Conv2D_2\",kernel_size=(4,4),strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),name=\"MaxPooling_2\"))\n",
        "    model.add(layers.SpatialDropout2D(rate=0.1,name=\"Dropoutlayer_2\"))\n",
        "    model.add(layers.Conv2D(filters=60,activation=\"ReLU\",name=\"Conv2D_3\",kernel_size=(4,4),strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),name=\"MaxPooling_3\"))\n",
        "    model.add(layers.SpatialDropout2D(rate=0.1,name=\"Dropoutlayer_3\"))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(Dense(64,activation=\"ReLU\",name=\"FC_Layer_1\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "    model.add(Dense(80,activation=\"ReLU\",name=\"FC_Layer_2\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "    model.add(Dense(25,activation=\"ReLU\",name=\"FC_Layer_3\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "    model.add(Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "    model._name=\"CNN2D\"\n",
        "    model.compile(loss='binary_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "    history=model.fit(input_train,output_train,epochs=20,batch_size=128,validation_data=[testinput,testoutput],class_weight=classweights)\n",
        "    return model,history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uToCthFTQYJu"
      },
      "outputs": [],
      "source": [
        "def CNN_BLSTM(input_train,output_train,classweights):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    model=Sequential()\n",
        "    model.add(layers.Reshape((1,122), input_shape=(None,122)))\n",
        "    model.add(keras.layers.Conv1D(filters=40,activation=\"tanh\",name=\"Conv1d1\",kernel_size=2,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=2,strides=1,name=\"MaxPooling1\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer1\"))\n",
        "    model.add(keras.layers.Conv1D(filters=60,activation=\"tanh\",name=\"Conv1d2\",kernel_size=3,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=3,strides=1,name=\"MaxPooling2\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer2\"))\n",
        "    model.add(keras.layers.Conv1D(filters=80,activation=\"tanh\",name=\"Conv1d3\",kernel_size=4,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(keras.layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling3\",padding=\"same\"))\n",
        "    model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer\"))\n",
        "    model.add(keras.layers.Bidirectional(layers.LSTM(50,activation=\"tanh\",name=\"BLSTM_layer\")))\n",
        "    model.add(keras.layers.Dropout(0.1))\n",
        "    model.add(Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "    model._name=\"CNNB_LSTM\"\n",
        "    monitor=EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=15,restore_best_weights=True)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=tf.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "    historty=model.fit(input_train,output_train,epochs=128,batch_size=128,validation_split=0.2,callbacks=[monitor],class_weight=classweights)\n",
        "    return model,historty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mriRkijiQYJv",
        "outputId": "9d5319d7-2d6d-4f9f-892d-b644044cd381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_9 (Reshape)         (None, 1, 122)            0         \n",
            "                                                                 \n",
            " Conv1d1 (Conv1D)            (None, 1, 40)             9800      \n",
            "                                                                 \n",
            " MaxPooling1 (MaxPooling1D)  (None, 1, 40)             0         \n",
            "                                                                 \n",
            " Dropout_layer1 (SpatialDrop  (None, 1, 40)            0         \n",
            " out1D)                                                          \n",
            "                                                                 \n",
            " Conv1d2 (Conv1D)            (None, 1, 60)             7260      \n",
            "                                                                 \n",
            " MaxPooling2 (MaxPooling1D)  (None, 1, 60)             0         \n",
            "                                                                 \n",
            " Dropout_layer2 (SpatialDrop  (None, 1, 60)            0         \n",
            " out1D)                                                          \n",
            "                                                                 \n",
            " Conv1d3 (Conv1D)            (None, 1, 80)             19280     \n",
            "                                                                 \n",
            " MaxPooling3 (MaxPooling1D)  (None, 1, 80)             0         \n",
            "                                                                 \n",
            " Dropout_layer (SpatialDropo  (None, 1, 80)            0         \n",
            " ut1D)                                                           \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100)              52400     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88,841\n",
            "Trainable params: 88,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(layers.Reshape((1,122), input_shape=(None,122)))\n",
        "model.add(keras.layers.Conv1D(filters=40,activation=\"tanh\",name=\"Conv1d1\",kernel_size=2,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "model.add(keras.layers.MaxPool1D(pool_size=2,strides=1,name=\"MaxPooling1\",padding=\"same\"))\n",
        "model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer1\"))\n",
        "model.add(keras.layers.Conv1D(filters=60,activation=\"tanh\",name=\"Conv1d2\",kernel_size=3,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "model.add(keras.layers.MaxPool1D(pool_size=3,strides=1,name=\"MaxPooling2\",padding=\"same\"))\n",
        "model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer2\"))\n",
        "model.add(keras.layers.Conv1D(filters=80,activation=\"tanh\",name=\"Conv1d3\",kernel_size=4,strides=1,padding=\"same\",use_bias=True,bias_initializer=initializers.Zeros(),kernel_initializer=\"glorot_uniform\"))\n",
        "model.add(keras.layers.MaxPool1D(pool_size=4,strides=1,name=\"MaxPooling3\",padding=\"same\"))\n",
        "model.add(keras.layers.SpatialDropout1D(rate=0.1,name=\"Dropout_layer\"))\n",
        "model.add(keras.layers.Bidirectional(layers.LSTM(50,activation=\"tanh\",name=\"BLSTM_layer\")))\n",
        "model.add(keras.layers.Dropout(0.1))\n",
        "model.add(Dense(1,activation=\"sigmoid\",name=\"output\", kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros()))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7BFV5LEQYJx",
        "outputId": "4a8e8180-2818-4e42-f6d6-a3a7726bbe05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#trainInput , trainOutput ,  scaler , encoder ,classweights= preprocessingBinaryClass2(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\KDDTrain+aggregateOneCls.csv\",cnn=False,cnn2d=False)\n",
        "#testInput , testOutput , *_ = preprocessingBinaryClass2(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\KDDTest+aggregateOneCls.csv\" ,cnn2d=False, hotencoder=encoder, cnn=False,train=False)\n",
        "#test21Input , test21Output , *_ = preprocessingBinaryClass2(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\KDDTest-21aggregateOneCls.csv\" ,cnn2d=False, cnn=False,hotencoder= encoder,train=False)\n",
        "\n",
        "trainInput , trainOutput , scaler , inEncoder , outEncoder,classweights = preprocessingFiveClasses(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\train5.csv\",cnn=False,cnn2d=False)\n",
        "testInput , testOutput , *_ = preprocessingFiveClasses(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\test5.csv\" ,cnn2d=False, inEncoder = inEncoder , outEncoder = outEncoder, cnn=False,train=False)\n",
        "test21Input , test21Output , *_ = preprocessingFiveClasses(r\"F:\\University\\Fourth year\\Bs.c\\NSL-KDD DataSet\\test521.csv\" ,cnn2d=False, cnn=False, inEncoder = inEncoder , outEncoder = outEncoder,train=False)\n",
        "\n",
        "testInput = fillData(trainInput , testInput)\n",
        "test21Input = fillData(trainInput , test21Input)\n",
        "trainInput=np.nan_to_num(trainInput)\n",
        "testInput=np.nan_to_num(testInput)\n",
        "test21Input=np.nan_to_num(test21Input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bC9tuDUQYJy",
        "outputId": "3c9d835a-4a09-4cee-bad5-4677d72faaee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   x0_Dos  x0_Probe  x0_R2L  x0_U2R  x0_normal\n",
            "0     1.0       0.0     0.0     0.0        0.0\n",
            "1     1.0       0.0     0.0     0.0        0.0\n",
            "2     0.0       0.0     0.0     0.0        1.0\n",
            "3     0.0       1.0     0.0     0.0        0.0\n",
            "4     0.0       1.0     0.0     0.0        0.0\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGiLwf2ZQYJz",
        "outputId": "ad124a34-5d1d-4d48-c455-6d1daf3cd192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "985/985 [==============================] - 15s 14ms/step - loss: 3.8912 - accuracy: 0.9027 - val_loss: 3.9497 - val_accuracy: 0.7717 - lr: 0.0500\n",
            "Epoch 2/75\n",
            "985/985 [==============================] - 12s 13ms/step - loss: 3.2585 - accuracy: 0.9089 - val_loss: 4.2845 - val_accuracy: 0.7452 - lr: 0.0500\n",
            "Epoch 3/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.7971 - accuracy: 0.9195 - val_loss: 4.0265 - val_accuracy: 0.7496 - lr: 0.0500\n",
            "Epoch 4/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.5660 - accuracy: 0.9361 - val_loss: 3.6608 - val_accuracy: 0.7500 - lr: 0.0500\n",
            "Epoch 5/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.4633 - accuracy: 0.9361 - val_loss: 3.0837 - val_accuracy: 0.7663 - lr: 0.0500\n",
            "Epoch 6/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.4760 - accuracy: 0.9307 - val_loss: 5.3650 - val_accuracy: 0.7841 - lr: 0.0500\n",
            "Epoch 7/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.5050 - accuracy: 0.9350 - val_loss: 3.2933 - val_accuracy: 0.7888 - lr: 0.0500\n",
            "Epoch 8/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.8943 - accuracy: 0.9317 - val_loss: 3.6912 - val_accuracy: 0.8023 - lr: 0.0500\n",
            "Epoch 9/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.7702 - accuracy: 0.9307 - val_loss: 4.1417 - val_accuracy: 0.7926 - lr: 0.0500\n",
            "Epoch 10/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.7801 - accuracy: 0.9268 - val_loss: 4.6343 - val_accuracy: 0.8023 - lr: 0.0500\n",
            "Epoch 11/75\n",
            "985/985 [==============================] - 17s 17ms/step - loss: 0.6231 - accuracy: 0.9267 - val_loss: 5.2126 - val_accuracy: 0.7854 - lr: 0.0500\n",
            "Epoch 12/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.7386 - accuracy: 0.9356 - val_loss: 7.7767 - val_accuracy: 0.7666 - lr: 0.0500\n",
            "Epoch 13/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.8315 - accuracy: 0.9307 - val_loss: 5.3963 - val_accuracy: 0.7858 - lr: 0.0500\n",
            "Epoch 14/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 1.0645 - accuracy: 0.9324 - val_loss: 7.8611 - val_accuracy: 0.7604 - lr: 0.0500\n",
            "Epoch 15/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 1.2895 - accuracy: 0.9370 - val_loss: 7.7601 - val_accuracy: 0.7617 - lr: 0.0500\n",
            "Epoch 16/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 2.3392 - accuracy: 0.9385 - val_loss: 6.0223 - val_accuracy: 0.7455 - lr: 0.0500\n",
            "Epoch 17/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.9911 - accuracy: 0.9390 - val_loss: 4.6385 - val_accuracy: 0.7271 - lr: 0.0500\n",
            "Epoch 18/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 1.3990 - accuracy: 0.9374 - val_loss: 5.2047 - val_accuracy: 0.7862 - lr: 0.0500\n",
            "Epoch 19/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3400 - accuracy: 0.9451 - val_loss: 4.8658 - val_accuracy: 0.7847 - lr: 0.0500\n",
            "Epoch 20/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.7955 - accuracy: 0.9416 - val_loss: 4.2917 - val_accuracy: 0.7936 - lr: 0.0500\n",
            "Epoch 21/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.2904 - accuracy: 0.9464 - val_loss: 4.1481 - val_accuracy: 0.7908 - lr: 0.0500\n",
            "Epoch 22/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.2890 - accuracy: 0.9448 - val_loss: 5.2743 - val_accuracy: 0.8083 - lr: 0.0500\n",
            "Epoch 23/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2783 - accuracy: 0.9473 - val_loss: 5.7086 - val_accuracy: 0.8044 - lr: 0.0500\n",
            "Epoch 24/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.3700 - accuracy: 0.9430 - val_loss: 4.9307 - val_accuracy: 0.7986 - lr: 0.0500\n",
            "Epoch 25/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3717 - accuracy: 0.9445 - val_loss: 5.4544 - val_accuracy: 0.7863 - lr: 0.0500\n",
            "Epoch 26/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.5081 - accuracy: 0.9458 - val_loss: 5.2110 - val_accuracy: 0.7390 - lr: 0.0500\n",
            "Epoch 27/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3112 - accuracy: 0.9419 - val_loss: 5.7252 - val_accuracy: 0.7834 - lr: 0.0500\n",
            "Epoch 28/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3278 - accuracy: 0.9419 - val_loss: 7.7495 - val_accuracy: 0.7763 - lr: 0.0500\n",
            "Epoch 29/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.3516 - accuracy: 0.9456 - val_loss: 5.9626 - val_accuracy: 0.7797 - lr: 0.0500\n",
            "Epoch 30/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.6033 - accuracy: 0.9485 - val_loss: 5.6819 - val_accuracy: 0.7893 - lr: 0.0500\n",
            "Epoch 31/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.5270 - accuracy: 0.9483 - val_loss: 11.2808 - val_accuracy: 0.7846 - lr: 0.0500\n",
            "Epoch 32/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 1.3529 - accuracy: 0.9486 - val_loss: 6.8535 - val_accuracy: 0.7991 - lr: 0.0500\n",
            "Epoch 33/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3253 - accuracy: 0.9539 - val_loss: 3.8071 - val_accuracy: 0.8127 - lr: 0.0500\n",
            "Epoch 34/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.5048 - accuracy: 0.9500 - val_loss: 4.4323 - val_accuracy: 0.7874 - lr: 0.0500\n",
            "Epoch 35/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.2711 - accuracy: 0.9513 - val_loss: 4.2301 - val_accuracy: 0.7431 - lr: 0.0500\n",
            "Epoch 36/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2992 - accuracy: 0.9532 - val_loss: 5.7331 - val_accuracy: 0.8039 - lr: 0.0500\n",
            "Epoch 37/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3791 - accuracy: 0.9522 - val_loss: 5.2221 - val_accuracy: 0.7948 - lr: 0.0500\n",
            "Epoch 38/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.3416 - accuracy: 0.9531 - val_loss: 5.1059 - val_accuracy: 0.7344 - lr: 0.0500\n",
            "Epoch 39/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 1.4894 - accuracy: 0.9477 - val_loss: 7.4059 - val_accuracy: 0.7816 - lr: 0.0500\n",
            "Epoch 40/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.4338 - accuracy: 0.9450 - val_loss: 23.3166 - val_accuracy: 0.7689 - lr: 0.0500\n",
            "Epoch 41/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 3.6919 - accuracy: 0.9542 - val_loss: 6.8921 - val_accuracy: 0.8074 - lr: 0.0500\n",
            "Epoch 42/75\n",
            "985/985 [==============================] - 15s 16ms/step - loss: 0.4189 - accuracy: 0.9466 - val_loss: 5.8773 - val_accuracy: 0.8023 - lr: 0.0500\n",
            "Epoch 43/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2877 - accuracy: 0.9530 - val_loss: 5.7131 - val_accuracy: 0.7946 - lr: 0.0500\n",
            "Epoch 44/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3035 - accuracy: 0.9580 - val_loss: 5.0352 - val_accuracy: 0.7543 - lr: 0.0500\n",
            "Epoch 45/75\n",
            "985/985 [==============================] - 15s 16ms/step - loss: 0.6364 - accuracy: 0.9586 - val_loss: 5.8939 - val_accuracy: 0.7948 - lr: 0.0500\n",
            "Epoch 46/75\n",
            "985/985 [==============================] - 14s 15ms/step - loss: 0.8821 - accuracy: 0.9473 - val_loss: 8.5569 - val_accuracy: 0.8080 - lr: 0.0500\n",
            "Epoch 47/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.4598 - accuracy: 0.9461 - val_loss: 6.4844 - val_accuracy: 0.8027 - lr: 0.0500\n",
            "Epoch 48/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2725 - accuracy: 0.9504 - val_loss: 7.5118 - val_accuracy: 0.8128 - lr: 0.0500\n",
            "Epoch 49/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.3569 - accuracy: 0.9440 - val_loss: 6.4260 - val_accuracy: 0.8085 - lr: 0.0500\n",
            "Epoch 50/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.5582 - accuracy: 0.9463 - val_loss: 6.2816 - val_accuracy: 0.8111 - lr: 0.0500\n",
            "Epoch 51/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3135 - accuracy: 0.9455 - val_loss: 8.1221 - val_accuracy: 0.8178 - lr: 0.0500\n",
            "Epoch 52/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2888 - accuracy: 0.9511 - val_loss: 7.9749 - val_accuracy: 0.8190 - lr: 0.0500\n",
            "Epoch 53/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3988 - accuracy: 0.9541 - val_loss: 6.2912 - val_accuracy: 0.8140 - lr: 0.0500\n",
            "Epoch 54/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.7702 - accuracy: 0.9540 - val_loss: 6.0365 - val_accuracy: 0.8034 - lr: 0.0500\n",
            "Epoch 55/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2930 - accuracy: 0.9552 - val_loss: 7.4228 - val_accuracy: 0.8023 - lr: 0.0500\n",
            "Epoch 56/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2977 - accuracy: 0.9588 - val_loss: 6.9193 - val_accuracy: 0.7644 - lr: 0.0500\n",
            "Epoch 57/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2727 - accuracy: 0.9587 - val_loss: 6.2470 - val_accuracy: 0.7895 - lr: 0.0500\n",
            "Epoch 58/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.6558 - accuracy: 0.9577 - val_loss: 4.7973 - val_accuracy: 0.8233 - lr: 0.0500\n",
            "Epoch 59/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2731 - accuracy: 0.9514 - val_loss: 4.7573 - val_accuracy: 0.8155 - lr: 0.0500\n",
            "Epoch 60/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2734 - accuracy: 0.9560 - val_loss: 5.3713 - val_accuracy: 0.8210 - lr: 0.0500\n",
            "Epoch 61/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2736 - accuracy: 0.9570 - val_loss: 5.0189 - val_accuracy: 0.8082 - lr: 0.0500\n",
            "Epoch 62/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2662 - accuracy: 0.9588 - val_loss: 4.2996 - val_accuracy: 0.8500 - lr: 0.0500\n",
            "Epoch 63/75\n",
            "985/985 [==============================] - 15s 16ms/step - loss: 0.3258 - accuracy: 0.9574 - val_loss: 5.2243 - val_accuracy: 0.8234 - lr: 0.0500\n",
            "Epoch 64/75\n",
            "985/985 [==============================] - 13s 14ms/step - loss: 0.3425 - accuracy: 0.9584 - val_loss: 4.3200 - val_accuracy: 0.8161 - lr: 0.0500\n",
            "Epoch 65/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2568 - accuracy: 0.9575 - val_loss: 4.5851 - val_accuracy: 0.8250 - lr: 0.0500\n",
            "Epoch 66/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.2585 - accuracy: 0.9551 - val_loss: 4.5271 - val_accuracy: 0.7900 - lr: 0.0500\n",
            "Epoch 67/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.3087 - accuracy: 0.9503 - val_loss: 6.3441 - val_accuracy: 0.8122 - lr: 0.0500\n",
            "Epoch 68/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.6544 - accuracy: 0.9505 - val_loss: 4.5349 - val_accuracy: 0.8230 - lr: 0.0500\n",
            "Epoch 69/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3278 - accuracy: 0.9573 - val_loss: 6.2102 - val_accuracy: 0.8391 - lr: 0.0500\n",
            "Epoch 70/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.2474 - accuracy: 0.9604 - val_loss: 6.7903 - val_accuracy: 0.7797 - lr: 0.0500\n",
            "Epoch 71/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.3216 - accuracy: 0.9596 - val_loss: 6.1419 - val_accuracy: 0.8279 - lr: 0.0500\n",
            "Epoch 72/75\n",
            "985/985 [==============================] - 15s 16ms/step - loss: 0.3520 - accuracy: 0.9556 - val_loss: 6.3082 - val_accuracy: 0.8240 - lr: 0.0500\n",
            "Epoch 73/75\n",
            "985/985 [==============================] - 15s 15ms/step - loss: 0.2551 - accuracy: 0.9552 - val_loss: 5.7470 - val_accuracy: 0.8271 - lr: 0.0500\n",
            "Epoch 74/75\n",
            "985/985 [==============================] - 14s 14ms/step - loss: 0.5699 - accuracy: 0.9606 - val_loss: 7.1525 - val_accuracy: 0.8046 - lr: 0.0500\n",
            "Epoch 75/75\n",
            "985/985 [==============================] - 16s 16ms/step - loss: 0.2568 - accuracy: 0.9629 - val_loss: 7.1318 - val_accuracy: 0.8050 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "model_2,historty_2=MULTI_CNN1D(trainInput,trainOutput,testInput,testOutput,classweights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1uvZWkrQYJ1",
        "outputId": "e4fd6c72-a7d5-4d13-87e6-bd3ba71fc99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "testPredict = model_2.predict(testInput)\n",
        "testPredict=(testPredict == testPredict.max(axis=1, keepdims=1)).astype(float)\n",
        "#testPredict=testPredict.argmax(axis=1)\n",
        "#testOutput=testOutput.reshape(testOutput.size,1)\n",
        "print(testPredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH1olSUFQYJ2",
        "outputId": "7d55c7d8-20ca-4a1b-df57-f4dbbafdd002"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.68770152 0.71690258 0.70842411 0.12       0.81784387] [0.03729355 0.03746825 0.07992524 0.00197425 0.20859971]\n"
          ]
        }
      ],
      "source": [
        "testPredict = model_2.predict(test21Input)\n",
        "testPredict=(testPredict == testPredict.max(axis=1, keepdims=1)).astype(float)\n",
        "cm=confusion_matrix(test21Output.values.argmax(axis=1),testPredict.argmax(axis=1))\n",
        "#print(cm)\n",
        "fp = cm.sum(axis=0) - np.diag(cm)  \n",
        "fn = cm.sum(axis=1) - np.diag(cm)\n",
        "tp = np.diag(cm)\n",
        "tn = cm.sum() - (fp + fn + tp)\n",
        "FPR = fp/(fp+tn)\n",
        "DR=tp/(tp+fn)\n",
        "ACC = (tp+tn)/(tp+fp+fn+tn)\n",
        "#cm_df=pd.DataFrame(cm,columns=['dos','probe','r2l','u2r','normal'])\n",
        "plt.figure(figsize=(12,10))\n",
        "ax=sns.heatmap(cm,annot=True,cmap='Blues')\n",
        "ax.xaxis.set_ticklabels(['dos','probe','r2l','u2r','normal'])\n",
        "ax.yaxis.set_ticklabels(['dos','probe','r2l','u2r','normal'])\n",
        "plt.title('confusion matrix')\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('predicted Value')\n",
        "plt.show()\n",
        "print(DR,FPR)\n",
        "#print(classification_report(testOutput,testPredict,digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZXlwHLSQYJ4",
        "outputId": "8a531009-e29b-4906-9ed3-128bc5330a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "985/985 [==============================] - 4s 4ms/step - loss: 0.1307 - accuracy: 0.9712\n",
            "{'Cost Function': 0.13065804541110992, 'Accuracy': 97.1200168132782}\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 7.1318 - accuracy: 0.8050\n",
            "{'Cost Function': 7.131762981414795, 'Accuracy': 80.50479292869568}\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 13.5519 - accuracy: 0.6332\n",
            "{'Cost Function': 13.551944732666016, 'Accuracy': 63.31645846366882}\n"
          ]
        }
      ],
      "source": [
        "print(predict_MLP_Classification(model_2,trainInput,trainOutput))\n",
        "print(predict_MLP_Classification(model_2,testInput,testOutput))\n",
        "print(predict_MLP_Classification(model_2,test21Input,test21Output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "lVLmcUeeQYJ6",
        "outputId": "28313acc-cc3c-4ae9-855f-645688deca39"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c8fcc0c82e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistorty_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBI_CNN1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainInput' is not defined"
          ]
        }
      ],
      "source": [
        "model_1,historty_1=BI_CNN1D(trainInput,trainOutput,testInput,testOutput,classweights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1lFF22IQYJ7",
        "outputId": "04d5713c-d8be-4d6e-e1c0-e9b9ed30325f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.37857604]\n",
            " [0.37857604]\n",
            " [0.37857604]\n",
            " ...\n",
            " [0.37857604]\n",
            " [1.        ]\n",
            " [0.37857604]]\n"
          ]
        }
      ],
      "source": [
        "pred=model_1.predict(testInput)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufshNcvtQYJ8"
      },
      "outputs": [],
      "source": [
        "def BI_Evalution_Metrics(model,testInput,testOutput):\n",
        "    pred=model_1.predict(testInput)\n",
        "    y_pred = (pred > 0.5)\n",
        "    y_true=testOutput.reshape(testOutput.size,1)\n",
        "    cf_matrix=confusion_matrix(y_true=y_true,y_pred=y_pred)\n",
        "    fp = cf_matrix.sum(axis=0) - np.diag(cf_matrix)  \n",
        "    fn = cf_matrix.sum(axis=1) - np.diag(cf_matrix)\n",
        "    tp = np.diag(cf_matrix)\n",
        "    tn = cf_matrix.sum() - (fp + fn + tp)\n",
        "    FPR = fp/(fp+tn)\n",
        "    DR=tp/(tp+fn)\n",
        "    ACC = (tp+tn)/(tp+fp+fn+tn)\n",
        "    ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "    #ax.set_title('Confusion matrix obtained by testing KDDTest21 dataset for binary classification\\n\\n');\n",
        "    ax.set_xlabel('\\nPredicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "    ## Ticket labels - List must be in alphabetical order\n",
        "    ax.xaxis.set_ticklabels(['Anormal','normal'])\n",
        "    ax.yaxis.set_ticklabels(['Anormal','normal'])\n",
        "    ## Display the visualization of the Confusion Matrix.\n",
        "    plt.show()\n",
        "    return ACC,DR,FPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqVrb0tJQYJ9",
        "outputId": "13c9605b-5685-426e-8b29-edd29a0c5ab0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Accuracy': array([0.914434, 0.914434]), 'Detection Rate': array([0.97132393, 0.83925445]), 'False positive Rate': array([0.16074555, 0.02867607])}\n"
          ]
        }
      ],
      "source": [
        "AC,DR,FPR=BI_Evalution_Metrics(model_1,testInput,testOutput)\n",
        "print({\"Accuracy\" : AC,\"Detection Rate\" : DR,\"False positive Rate\" : FPR})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmq2VuE7QYJ-",
        "outputId": "1fb946b4-77f5-46f3-db25-a886fa4886b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "985/985 [==============================] - 4s 4ms/step - loss: 0.3703 - accuracy: 0.8600\n",
            "{'Cost Function': 0.37027260661125183, 'Accuracy': 86.00493669509888}\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 3.0984 - accuracy: 0.9144\n",
            "{'Cost Function': 3.0983974933624268, 'Accuracy': 91.4434015750885}\n",
            "93/93 [==============================] - 0s 5ms/step - loss: 5.7280 - accuracy: 0.8788\n",
            "{'Cost Function': 5.727993011474609, 'Accuracy': 87.88185715675354}\n"
          ]
        }
      ],
      "source": [
        "print(predict_MLP_Classification(model_1,trainInput,trainOutput))\n",
        "print(predict_MLP_Classification(model_1,testInput,testOutput))\n",
        "print(predict_MLP_Classification(model_1,test21Input,test21Output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtp6fxhiQYKC",
        "outputId": "2012f413-8606-44ba-efbe-fd221ee72c0f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x648 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([])\n",
        "#df[\"KDDTest+\"]=[69.52,80.67,81.67,89.59,91.4]\n",
        "#df[\"KDDTest-21\"]=[42.29,63.26,63.97,81.95,87.8]\n",
        "df[\"KDDTest+\"]=[86.19,82.92,81.29,85.42,86.56,84.7]\n",
        "df[\"KDDTest-21\"]=[0,68.30,64.67,0,80.09,71.24]\n",
        "df[\"algorithm\"]=['FDDNN[42]','CNN2D[43]','RNN[30]','NDAE[28]',\"MLP\",\"CNN1D\"]\n",
        "\n",
        "ax = df.plot.bar(x='algorithm', y=['KDDTest+','KDDTest-21'], figsize=(15, 9),color=[\"b\",\"orange\"])\n",
        "\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "#remove all x-labels since the table will be used instead\n",
        "plt.xlabel('')\n",
        "plt.xticks([])\n",
        "\n",
        "table_columns = df['algorithm'].values.tolist()\n",
        "open = df['KDDTest+'].values.tolist()\n",
        "closed = df['KDDTest-21'].values.tolist()\n",
        "table_data = [open, closed]\n",
        "table_rows = df.columns.values.tolist()[0:2]\n",
        "the_table=plt.table(cellText=table_data, rowLabels=table_rows, colLabels=table_columns, loc='bottom',rowColours=[\"b\",\"orange\"])\n",
        "the_table.auto_set_font_size(False)\n",
        "the_table.set_fontsize(17)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.29)\n",
        "cell_dict = the_table.get_celld()\n",
        "for i in cell_dict:\n",
        "    # print(i)\n",
        "    cell_dict[i].set_height(0.10)\n",
        "    cell_dict[i].set_width(0.167)\n",
        "plt.savefig(\"myimage.png\", dpi=1500)\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPu8MayRQYKF",
        "outputId": "79aeeda3-6ef3-4eac-fcfa-4f564453bd90"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.style.use(['seaborn-paper', 'seaborn-whitegrid'])\n",
        "plt.style.use(['seaborn'])\n",
        "sns.set(palette='colorblind')\n",
        "matplotlib.rc(\"font\", family=\"Times New Roman\", size=12)\n",
        "\n",
        "labels = ['n=1','n=2','n=3','n=4','n=5']\n",
        "a = [98.8,98.8,98.8,98.8,98.8]\n",
        "b = [98.6,97.8,97.0,96.2,95.4]\n",
        "bar_width = 0.20\n",
        "data = [a,b]\n",
        "\n",
        "colors = sns.color_palette(palette='colorblind')\n",
        "columns = ('n=1', 'n=2', 'n=3', 'n=4', 'n=5')\n",
        "\n",
        "index = np.arange(len(labels))\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "plt.bar(index, a, bar_width)\n",
        "plt.bar(index+bar_width+.02, b, bar_width)\n",
        "plt.table(cellText=data,\n",
        "          rowLabels=[' a ', ' b '],\n",
        "          rowColours=colors,\n",
        "          colLabels=columns,\n",
        "          loc='bottom',\n",
        "          bbox=[0, 0.225, 1, 0.2])\n",
        "\n",
        "fig.subplots_adjust(bottom=0.1)\n",
        "\n",
        "plt.ylabel('Some y label which effect the bottom padding!')\n",
        "plt.xticks([])\n",
        "plt.title('Some title')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Anomaly_baised_Intrusion_detection_system_CNN1D.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}